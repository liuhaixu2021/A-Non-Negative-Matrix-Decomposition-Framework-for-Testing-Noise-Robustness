{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6p62zfR0CXK"
      },
      "source": [
        "# Import Library and Download Datasets\n",
        "Data link is in here, if wget not work you can download from google drive and upload to content path\n",
        "https://drive.google.com/file/d/1tv1fIIFlwSkkCIFBSHIjqqJss59ToYz6/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXkeD713cWn7"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import time\n",
        "import warnings\n",
        "from abc import ABC\n",
        "from math import sqrt\n",
        "from numbers import Integral, Real\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, normalized_mutual_info_score\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "from scipy import linalg\n",
        "from PIL import Image\n",
        "from collections import Counter\n",
        "from sklearn.cluster import KMeans\n",
        "import time\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkbm36Aqt57g"
      },
      "outputs": [],
      "source": [
        "!wget --header=\"Host: drive.usercontent.google.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\" --header=\"Accept-Language: zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6\" --header=\"Cookie: HSID=AqK8DRIVZrNtHDQEM; SSID=AF8GbXclnoQKbndEK; APISID=eaYPuocswpo7W9-H/AOCjbMPSZJ096e5h4; SAPISID=xTIl5TE60VtPYf3j/A-54gZvfpsOMhgwjL; __Secure-1PAPISID=xTIl5TE60VtPYf3j/A-54gZvfpsOMhgwjL; __Secure-3PAPISID=xTIl5TE60VtPYf3j/A-54gZvfpsOMhgwjL; SID=g.a000nwiBaUsi6GOos5qwiCAzn7-ZhQm918oX0Xqog9XWXFAhtx4_ZngLciamwWcT5nURbScnKwACgYKATASAQASFQHGX2MiQUUCe2tzgS6X-NL3HA8prxoVAUF8yKr0RVnsjZil3lVmNMD_zlCe0076; __Secure-1PSID=g.a000nwiBaUsi6GOos5qwiCAzn7-ZhQm918oX0Xqog9XWXFAhtx4_-L5NGsjGkY8bODGhVP1CXgACgYKAWsSAQASFQHGX2MiqEWkSIH_mDn_XbSIn0PZ_RoVAUF8yKqh4hIaFLXTaFagmPAkmTpB0076; __Secure-3PSID=g.a000nwiBaUsi6GOos5qwiCAzn7-ZhQm918oX0Xqog9XWXFAhtx4_2k-SeL0aEAW1iN-ei2vX2wACgYKATQSAQASFQHGX2MiErvzoykH-Xm8oSXESUJuMRoVAUF8yKpsebmGTkobkLR6ev1dgZRn0076; SEARCH_SAMESITE=CgQIkZwB; AEC=AVYB7crFgh82n3n5Vx_S_wBruUtOWux2ywUcWao2Wu3a5ttBxbSiVjfvug; NID=517=1k5FYkn8M-P_YKb1T_ZdOebcDZNwi9_ADpDL1V1TVHtEUeBAGO1i9zo4Yr-zvaCnMhLwWtU8_xFexJq3SYDcegD_S0MJNqQ4zgCEGD0NSZAh5NxH3UOhZDSk__z25-HlNluq9TWyLncaqrzR1IdJh5cPO8lZHKfalqVsTPKR9042EWXSPn1VlHc3Sk_8_C6LqFWFAWCKm7dGOm7KmoOxewCvxi2JB8m8v9zEBcwV9UDXCp_DNSJLuSP2gWBr1B2rImJcKrFiykWdlsaRLF3FiiXpM3-UkdAtC_3-UJezKMUT6aksz5LFTFBqPq7jzTrsplYm6bgGlfq-IqDUbL-GCex4eagFa6HHAzVh-Ha56Gx8F6mHUFpLEoCbwBt3IADHhKNsCSAoQl7hYm8giIa6x7jNXWAxsvoOGxm5vkdq_Q-Tlx3qEbLR-MSJFjZ2it-RoSPvETxC1GozsiTZDeMOYwcrjs0N_PQ1k3ijpA48f4z5YRDrUYiBPbHQf0BPedLBxgWzA513lAI5wT_Ynj7tKQaZPp0QPzmcrVGSLeLP5-iQievyzNokAPUPVAkp8xh2px4-3RwnoUECGNNoYr5B21oWQul5dv7St5po7PoPw8XOeNlEtjKIJFID2i_yRGNehue1NOX6FYsIW5Tb_Pj-eP9eAjtIwG5_s288l8Ab4kbt49SZpz-mFSqyWn7-qMm9o2ecWP9VZEaznVcYQZqnWgTWGayw9sQP5Pw; __Secure-1PSIDTS=sidts-CjEBQlrA-IqahnQSUEU4FqXSAgtLU9srhyUcFyh8sqXTNjZ5mYBT6EE60YxSnQAPRtbWEAA; __Secure-3PSIDTS=sidts-CjEBQlrA-IqahnQSUEU4FqXSAgtLU9srhyUcFyh8sqXTNjZ5mYBT6EE60YxSnQAPRtbWEAA; SIDCC=AKEyXzXXJUxxf1dU3IG2iEYtnlrq-gsOi4Vide6X1OG2eexlhnKR4qXZPT5HbaslMe5ETrLLpcRpqA; __Secure-1PSIDCC=AKEyXzUTLXKxpliRsRXJ2ckCuusHIQ5Dw1DkQDx5vJGaQFGvOuqEBOIbTv-QxxTgq0laTEKkoMn8; __Secure-3PSIDCC=AKEyXzVKf2iO_7kVDF1jIWfkZnwm5no0CEU4e8OJJceC2rcWz5M-NcraOcLc3Ox-zEXhaSfPh6AA\" --header=\"Connection: keep-alive\" \"https://drive.usercontent.google.com/download?id=1tv1fIIFlwSkkCIFBSHIjqqJss59ToYz6&export=download&authuser=0&confirm=t&uuid=2c49a6dc-58f0-4f6b-a9c3-0cfb7cfcaf0a&at=AO7h07fHFAIP4xqhNGL8GcqTR0ar:1727163600772\" -c -O 'data.zip'\n",
        "!unzip data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWuP4T2BgEZz"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def process_pgm_images(input_dir, output_dir, target_size=(168,192)):\n",
        "    \"\"\"\n",
        "    Traverse the given directory to find all `.pgm` images, resize them if necessary,\n",
        "    convert them to numpy arrays, and save them in `.npy` format.\n",
        "\n",
        "    Also combines all processed images into a single numpy array and generates corresponding labels.\n",
        "\n",
        "    :param input_dir: Directory containing the images in subfolders\n",
        "    :param output_dir: Directory where `.npy` files will be saved\n",
        "    :param target_size: Target size to resize images to (height, width)\n",
        "    :return: Combined numpy array of all processed images and corresponding labels\n",
        "    \"\"\"\n",
        "    # Ensure the output directory exists\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # List to store all images as numpy arrays and corresponding labels\n",
        "    all_images = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Dictionary to store image count per folder\n",
        "    folder_image_count = {}\n",
        "\n",
        "    # Traverse through the input directory\n",
        "    label_counter = 0\n",
        "    for folder_name in os.listdir(input_dir):\n",
        "        folder_path = os.path.join(input_dir, folder_name)\n",
        "\n",
        "        # Check if it's a directory\n",
        "        if os.path.isdir(folder_path):\n",
        "            image_count = 0\n",
        "            for file_name in os.listdir(folder_path):\n",
        "                if file_name.endswith('.pgm'):\n",
        "                  if file_name.endswith('Ambient.pgm'):\n",
        "                      continue\n",
        "                  else:\n",
        "                    file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "                    # Read the .pgm image and convert to numpy array\n",
        "                    img = Image.open(file_path)\n",
        "\n",
        "                    # Check if the image size is not the target size, and resize if necessary\n",
        "                    if img.size != target_size:\n",
        "                        print(f\"Resizing image {file_name} from size {img.size} to {target_size}\")\n",
        "                        img = img.resize(target_size, Image.LANCZOS)\n",
        "\n",
        "                    # Convert image to numpy array\n",
        "                    img_np = np.array(img)\n",
        "\n",
        "                    # Append the image array to the list for combined output\n",
        "                    all_images.append(img_np)\n",
        "\n",
        "                    # Append the corresponding label (current folder's label)\n",
        "                    all_labels.append(label_counter)\n",
        "\n",
        "                    # Define the output file name\n",
        "                    output_file = os.path.join(output_dir, f\"{folder_name}_{file_name.replace('.pgm', '.npy')}\")\n",
        "\n",
        "                    # Save the numpy array as .npy\n",
        "                    np.save(output_file, img_np)\n",
        "                    print(f\"Processed and saved {output_file}\")\n",
        "\n",
        "                    # Increment the image count for this folder\n",
        "                    image_count += 1\n",
        "\n",
        "            # Store the image count for the folder\n",
        "            folder_image_count[folder_name] = image_count\n",
        "            # Increment the label counter\n",
        "            label_counter += 1\n",
        "\n",
        "    # Output the number of images per folder\n",
        "    for folder, count in folder_image_count.items():\n",
        "        print(f\"Folder '{folder}' contains {count} images\")\n",
        "\n",
        "    # Convert the list of all images to a numpy array\n",
        "    combined_images_np = np.array(all_images)\n",
        "    labels_np = np.array(all_labels)\n",
        "\n",
        "    print(f\"Combined array shape: {combined_images_np.shape}\")\n",
        "    print(f\"Labels array shape: {labels_np.shape}\")\n",
        "\n",
        "    # Return the combined numpy array of all images and the labels array\n",
        "    return combined_images_np, labels_np\n",
        "\n",
        "\n",
        "# Example usage for YaleB dataset\n",
        "input_dir_YaleB = \"/content/data/CroppedYaleB/\"\n",
        "output_dir_YaleB = \"Processed_YaleB\"\n",
        "yaleb_images, yaleb_labels = process_pgm_images(input_dir_YaleB, output_dir_YaleB, target_size=(42,48))\n",
        "\n",
        "# Example usage for ORL dataset\n",
        "input_dir_ORL = \"/content/data/ORL/\"\n",
        "output_dir_ORL = \"Processed_ORL\"\n",
        "orl_images, orl_labels = process_pgm_images(input_dir_ORL, output_dir_ORL, target_size=(30,37))\n",
        "\n",
        "# Check shapes of the processed images and labels\n",
        "print(\"YaleB images shape:\", yaleb_images.shape)\n",
        "print(\"YaleB labels shape:\", yaleb_labels.shape)\n",
        "\n",
        "print(\"ORL images shape:\", orl_images.shape)\n",
        "print(\"ORL labels shape:\", orl_labels.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-O68j77_siH"
      },
      "source": [
        "# Noisy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Salt and Pepper Noise(S&P)"
      ],
      "metadata": {
        "id": "cXRi0vht__G7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CN5IxFSNHVOA"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def add_salt_and_pepper_noise(image, prob=0.1):\n",
        "    \"\"\"\n",
        "    Adds salt-and-pepper noise to a normalized image with pixel values in the range [0, 1].\n",
        "    :param image: Input image, numpy array with pixel values in the range [0, 1].\n",
        "    :param prob: Probability of adding salt and pepper noise (turning some pixels to 0 or 1).\n",
        "    :return: Image with salt-and-pepper noise, numpy array.\n",
        "    \"\"\"\n",
        "    # Generate random salt and pepper noise masks\n",
        "    salt_mask = np.random.rand(*image.shape[:2]) <prob\n",
        "    pepper_mask = np.random.rand(*image.shape[:2]) < prob\n",
        "\n",
        "    # Apply the noise to the image\n",
        "    noisy_image = np.copy(image)\n",
        "    noisy_image[salt_mask] = 1  # White\n",
        "    noisy_image[pepper_mask] = 0  # Black\n",
        "\n",
        "    return noisy_image\n",
        "\n",
        "# Load the .pgm image\n",
        "image_path = '/content/data/CroppedYaleB/yaleB01/yaleB01_P00A+000E+20.pgm'\n",
        "img = Image.open(image_path)\n",
        "img = img.resize((42, 48))\n",
        "\n",
        "# Convert the image to a numpy array and normalize it to the range [0, 1]\n",
        "img_np = np.array(img) / 255.0\n",
        "\n",
        "# Add salt-and-pepper noise to the image with different probabilities\n",
        "noisy_img = add_salt_and_pepper_noise(img_np, prob=0.01)\n",
        "noisy_img2 = add_salt_and_pepper_noise(img_np, prob=0.05)\n",
        "noisy_img3 = add_salt_and_pepper_noise(img_np, prob=0.1)\n",
        "\n",
        "# Plot the original image and the noisy images\n",
        "fig, axs = plt.subplots(1, 4, figsize=(16, 10), dpi=300)\n",
        "\n",
        "# Display the original grayscale image\n",
        "axs[0].imshow(img_np, cmap='gray')\n",
        "axs[0].set_title('Original Image', fontsize=20)\n",
        "axs[0].axis('off')\n",
        "\n",
        "# Display the grayscale image with 1% salt-and-pepper noise\n",
        "axs[1].imshow(noisy_img, cmap='gray')\n",
        "axs[1].set_title('S&P Noise(1%)', fontsize=20)\n",
        "axs[1].axis('off')\n",
        "\n",
        "# Display the grayscale image with 5% salt-and-pepper noise\n",
        "axs[2].imshow(noisy_img2, cmap='gray')\n",
        "axs[2].set_title('S&P Noise(5%)', fontsize=20)\n",
        "axs[2].axis('off')\n",
        "\n",
        "# Display the grayscale image with 10% salt-and-pepper noise\n",
        "axs[3].imshow(noisy_img3, cmap='gray')\n",
        "axs[3].set_title('S&P Noise(10%)', fontsize=20)\n",
        "axs[3].axis('off')\n",
        "\n",
        "# Show the images\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gaussian Noise"
      ],
      "metadata": {
        "id": "6P7cP8u1AGH0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjgun17bId1b"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def add_gaussian_noise(image, mean=0, noise_std=0.01):\n",
        "    \"\"\"\n",
        "    Adds Gaussian noise to an image.\n",
        "    :param image: Input image, numpy array with pixel values in the range [0, 1].\n",
        "    :param mean: Mean of the Gaussian noise.\n",
        "    :param noise_std: Standard deviation of the Gaussian noise.\n",
        "    :return: Image with Gaussian noise, numpy array.\n",
        "    \"\"\"\n",
        "    # Generate Gaussian noise\n",
        "    gaussian_noise = np.random.normal(mean, noise_std, image.shape)\n",
        "\n",
        "    # Add the noise to the image and clip the result to the range [0, 1]\n",
        "    noisy_image = np.clip(image + gaussian_noise, 0, 1)\n",
        "\n",
        "    return noisy_image\n",
        "\n",
        "# Load the .pgm image\n",
        "image_path = '/content/data/CroppedYaleB/yaleB01/yaleB01_P00A+000E+20.pgm'\n",
        "img = Image.open(image_path)\n",
        "img = img.resize((42, 48))\n",
        "\n",
        "# Convert the image to a numpy array and normalize it to the range [0, 1]\n",
        "img_np = np.array(img) / 255.0\n",
        "\n",
        "# Add Gaussian noise with different standard deviations\n",
        "noisy_img = add_gaussian_noise(img_np, mean=0, noise_std=0.05)\n",
        "noisy_img2 = add_gaussian_noise(img_np, mean=0, noise_std=0.1)\n",
        "noisy_img3 = add_gaussian_noise(img_np, mean=0, noise_std=0.25)\n",
        "\n",
        "# Plot the original and noisy images\n",
        "fig, axs = plt.subplots(1, 4, figsize=(16, 10), dpi=300)\n",
        "\n",
        "# Display the original grayscale image\n",
        "axs[0].imshow(img_np, cmap='gray')\n",
        "axs[0].set_title('Original Image', fontsize=20)\n",
        "axs[0].axis('off')\n",
        "\n",
        "# Display the grayscale image with Gaussian noise (std=0.05)\n",
        "axs[1].imshow(noisy_img, cmap='gray')\n",
        "axs[1].set_title('Gaussian(std=0.05)', fontsize=20)\n",
        "axs[1].axis('off')\n",
        "\n",
        "# Display the grayscale image with Gaussian noise (std=0.1)\n",
        "axs[2].imshow(noisy_img2, cmap='gray')\n",
        "axs[2].set_title('Gaussian(std=0.1)', fontsize=20)\n",
        "axs[2].axis('off')\n",
        "\n",
        "# Display the grayscale image with Gaussian noise (std=0.25)\n",
        "axs[3].imshow(noisy_img3, cmap='gray')\n",
        "axs[3].set_title('Gaussian(std=0.25)', fontsize=20)\n",
        "axs[3].axis('off')\n",
        "\n",
        "# Show the images\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Block Occlusion Noise"
      ],
      "metadata": {
        "id": "i01YpE1uAMJT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66UsdJWiJEUi"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def add_block_occlusion_noise(image, block_size=14, num_blocks=1):\n",
        "    \"\"\"\n",
        "    Adds block occlusion noise to an image. The pixel values of the occlusion block are set to 255.\n",
        "    :param image: Input image, numpy array with pixel values in the range [0, 1].\n",
        "    :param block_size: Size of the occlusion block, default is 14.\n",
        "    :param num_blocks: Number of blocks to add, default is 1.\n",
        "    :return: Image with block occlusion noise, numpy array.\n",
        "    \"\"\"\n",
        "    # Get the height and width of the image\n",
        "    h, w = image.shape\n",
        "\n",
        "    # Create a copy of the image to add noise\n",
        "    noisy_image = np.copy(image)\n",
        "\n",
        "    for _ in range(num_blocks):\n",
        "        # Randomly select the top-left corner coordinates of the block\n",
        "        x = np.random.randint(0, w - block_size)\n",
        "        y = np.random.randint(0, h - block_size)\n",
        "\n",
        "        # Set the pixel values within the block to 1 (255 corresponds to 1 in normalized images)\n",
        "        noisy_image[y:y + block_size, x:x + block_size] = 1\n",
        "\n",
        "    return noisy_image\n",
        "\n",
        "# Load the .pgm image\n",
        "image_path = '/content/data/CroppedYaleB/yaleB01/yaleB01_P00A+000E+20.pgm'\n",
        "img = Image.open(image_path)\n",
        "img = img.resize((42, 48))\n",
        "\n",
        "# Convert the image to a numpy array and normalize it to the range [0, 1]\n",
        "img_np = np.array(img) / 255.0\n",
        "\n",
        "# Add block occlusion noise\n",
        "noisy_img = add_block_occlusion_noise(img_np, block_size=10, num_blocks=1)\n",
        "noisy_img2 = add_block_occlusion_noise(img_np, block_size=14, num_blocks=1)\n",
        "noisy_img3 = add_block_occlusion_noise(img_np, block_size=10, num_blocks=2)\n",
        "\n",
        "# Plot the original and noisy images\n",
        "fig, axs = plt.subplots(1, 4, figsize=(16, 10), dpi=300)\n",
        "\n",
        "# Display the original grayscale image\n",
        "axs[0].imshow(img_np, cmap='gray')\n",
        "axs[0].set_title('Original Image', fontsize=20)\n",
        "axs[0].axis('off')\n",
        "\n",
        "# Display the grayscale image with block occlusion noise (block size 10, 1 block)\n",
        "axs[1].imshow(noisy_img, cmap='gray')\n",
        "axs[1].set_title('Block(size=10,num=1)', fontsize=18)\n",
        "axs[1].axis('off')\n",
        "\n",
        "# Display the grayscale image with block occlusion noise (block size 14, 1 block)\n",
        "axs[2].imshow(noisy_img2, cmap='gray')\n",
        "axs[2].set_title('Block(size=14,num=1)', fontsize=18)\n",
        "axs[2].axis('off')\n",
        "\n",
        "# Display the grayscale image with block occlusion noise (block size 10, 2 blocks)\n",
        "axs[3].imshow(noisy_img3, cmap='gray')\n",
        "axs[3].set_title('Block(size=10,num=2)', fontsize=18)\n",
        "axs[3].axis('off')\n",
        "\n",
        "# Show the images\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GWqdj65gCWM"
      },
      "source": [
        "# NMF Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e33PFIG1U6A"
      },
      "source": [
        "## NMF with Noisy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mlgvj0o5hSUN"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "class NMFWithNoise:\n",
        "    def __init__(self, n_components=10,\n",
        "            method=\"L2\",\n",
        "            max_iter=1000,\n",
        "            tol=1e-4,\n",
        "            early_stopping=True,\n",
        "            patience=10,\n",
        "            min_delta=1e-3,\n",
        "            verbose=500,\n",
        "            noise_std=0.01,\n",
        "            prob=0.01,\n",
        "            block_size=12,\n",
        "            num_blocks=1,\n",
        "            is_noise=True,\n",
        "            noise_type='gaussian',\n",
        "            normalize=True,\n",
        "            imgsize=(30,37)):\n",
        "        \"\"\"\n",
        "        Initializes the NMFWithNoise class with various parameters.\n",
        "\n",
        "        :param n_components: Number of components for NMF, default is 10.\n",
        "        :param method: The optimization method, choices are 'L2', 'L1', 'L21', default is 'L2'.\n",
        "        :param max_iter: Maximum number of iterations for the algorithm, default is 1000.\n",
        "        :param tol: Tolerance for stopping criteria based on loss, default is 1e-4.\n",
        "        :param early_stopping: Whether to use early stopping, default is True.\n",
        "        :param patience: Number of iterations with no improvement to wait for before stopping early, default is 10.\n",
        "        :param min_delta: Minimum change in loss to qualify as an improvement, default is 1e-3.\n",
        "        :param verbose: Interval (in epochs) at which to print progress, default is 500.\n",
        "        :param noise_std: Standard deviation for Gaussian noise, default is 0.01.\n",
        "        :param prob: Probability for salt-and-pepper noise, default is 0.01.\n",
        "        :param block_size: Size of occlusion block for block noise, default is 12.\n",
        "        :param num_blocks: Number of occlusion blocks to add, default is 1.\n",
        "        :param is_noise: Boolean flag to add noise, if False no noise will be added, default is True.\n",
        "        :param noise_type: Type of noise to add ('gaussian', 'block', 'salt_and_pepper'), default is 'gaussian'.\n",
        "        :param normalize: Whether to normalize input data, default is True.\n",
        "        :param imgsize: Tuple specifying the height and width of the image, default is (30, 37).\n",
        "        \"\"\"\n",
        "        self.n_components = n_components\n",
        "        self.max_iter = max_iter\n",
        "        self.tol = tol\n",
        "        self.noise_std = noise_std  # Standard deviation for noise\n",
        "        self.noise_type = noise_type  # Type of noise to apply\n",
        "        self.normalize = normalize\n",
        "        self.early_stopping = early_stopping  # Enable early stopping\n",
        "        self.patience = patience  # Patience for early stopping\n",
        "        self.min_delta = min_delta  # Minimum loss improvement to continue training\n",
        "        self.verbose = verbose  # Verbosity level\n",
        "        self.imgsize = imgsize  # Image size for reshaping\n",
        "        self.method = method\n",
        "        self.block_size = block_size\n",
        "        self.num_blocks = num_blocks\n",
        "        self.prob=prob\n",
        "        self.is_noise = is_noise\n",
        "\n",
        "        # To store metrics per epoch\n",
        "        self.losses = []\n",
        "        self.rres = []\n",
        "        self.accuracies = []\n",
        "        self.nmis = []\n",
        "        self.H = None  # Store learned H for future use\n",
        "        self.scaler = None  # Placeholder for MinMaxScaler if normalization is used\n",
        "\n",
        "    def add_noise(self, X):\n",
        "\n",
        "        X = X.astype(np.float64)  # Ensure data type is float\n",
        "\n",
        "        # Get batch size and flattened dimensions\n",
        "        batch_size, flattened_size = X.shape\n",
        "\n",
        "        # Calculate height and width\n",
        "        height, width = self.imgsize\n",
        "\n",
        "        # Ensure flattened size matches the expected height * width\n",
        "        assert flattened_size == height * width, \"Flattened size does not match the specified image dimensions\"\n",
        "\n",
        "        # print(\"Original shape:\", X.shape)\n",
        "\n",
        "        # Initialize matrix to store noisy images\n",
        "        X_noisy = np.zeros_like(X)\n",
        "\n",
        "        # Process each image in the batch\n",
        "        for i in range(batch_size):\n",
        "            # Reshape the flattened image back to its 2D shape (height, width)\n",
        "            single_image = X[i].reshape(height, width)\n",
        "\n",
        "            # Process each image in the batch\n",
        "            if self.is_noise:\n",
        "                if self.noise_type == 'gaussian':\n",
        "                    # Call external function to add Gaussian noise\n",
        "                    noisy_image = add_gaussian_noise(single_image, noise_std=self.noise_std)\n",
        "                elif self.noise_type == 'block':\n",
        "                    # Call external function to add block occlusion noise\n",
        "                    noisy_image = add_block_occlusion_noise(single_image, block_size=self.block_size, num_blocks=self.num_blocks)\n",
        "                elif self.noise_type == 'salt_and_pepper':\n",
        "                    # Call external function to add salt and pepper noise\n",
        "                    noisy_image = add_salt_and_pepper_noise(single_image, prob=self.prob)\n",
        "                else:\n",
        "                    # Raise an error if the noise type is not recognized\n",
        "                    raise ValueError(f\"Unknown noise type: {self.noise_type}\")\n",
        "\n",
        "                # Flatten the 2D noisy image back to the original shape\n",
        "                X_noisy[i] = noisy_image.flatten()\n",
        "            else:\n",
        "                # If no noise is applied, just copy the original image\n",
        "                X_noisy[i] = single_image.flatten()\n",
        "\n",
        "        # print(\"Processed noisy images:\", X_noisy.shape)\n",
        "\n",
        "        return np.clip(X_noisy, 0, 1)# Clip the values to the range [0, 1]\n",
        "\n",
        "\n",
        "    def frobenius_norm(self, A):\n",
        "        \"\"\"Calculate the Frobenius norm\"\"\"\n",
        "        return np.sqrt(np.sum(A ** 2))\n",
        "\n",
        "    def normalize_data(self, X):\n",
        "        \"\"\"Normalize data if required\"\"\"\n",
        "        if self.normalize:\n",
        "            self.scaler = MinMaxScaler()\n",
        "            X = self.scaler.fit_transform(X)\n",
        "        return X\n",
        "\n",
        "    def denormalize_data(self, X):\n",
        "        \"\"\"Denormalize data if normalization was applied\"\"\"\n",
        "        if self.normalize and self.scaler is not None:\n",
        "            X = self.scaler.inverse_transform(X)\n",
        "        return X\n",
        "\n",
        "    def compute_rre(self, V, WH):\n",
        "        \"\"\"Compute the Relative Reconstruction Error (RRE)\"\"\"\n",
        "        numerator = self.frobenius_norm(V - WH)\n",
        "        denominator = self.frobenius_norm(V)\n",
        "        return numerator / denominator\n",
        "\n",
        "    def assign_cluster_label(self, X, Y):\n",
        "        \"\"\"Assign cluster labels using KMeans and match them with true labels.\"\"\"\n",
        "\n",
        "        kmeans = KMeans(n_clusters=len(set(Y))).fit(X)\n",
        "        Y_pred = np.zeros(Y.shape)\n",
        "        for i in set(kmeans.labels_):\n",
        "            ind = kmeans.labels_ == i\n",
        "            Y_pred[ind] = Counter(Y[ind]).most_common(1)[0][0]  # Assign label\n",
        "        return Y_pred\n",
        "\n",
        "    def compute_loss(self, X, WH, W, H, n_features, n_samples):\n",
        "        \"\"\"Compute the loss function\"\"\"\n",
        "        if self.method == \"L2\":\n",
        "            return 0.5 * self.frobenius_norm(X - WH) ** 2\n",
        "        elif self.method == \"L1\":\n",
        "            return np.sum(np.abs(X - W.dot(H)))\n",
        "        elif self.method == \"L21\":\n",
        "            return np.sum(np.sqrt(np.sum(np.square(X - W.dot(H)), axis=0)))\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown method: {self.method}\")\n",
        "\n",
        "    def update_weight(self, X, H, W):\n",
        "        if self.method == \"L2\":\n",
        "            return 1\n",
        "        elif self.method == \"L1\":\n",
        "            #eps = X.var() / W.shape[1]\n",
        "            eps = 1e-10\n",
        "            return 1/ (np.sqrt(np.square(X - W.dot(H))) + eps ** 2)\n",
        "\n",
        "        elif self.method == \"L21\":\n",
        "            return 1 / np.sqrt(np.sum(np.square(X - W.dot(H)), axis=0))\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown method: {self.method}\")\n",
        "\n",
        "    def fit_transform(self, X, Y_true=None, n_clusters=None,metrics=True):\n",
        "        \"\"\"Perform NMF without mini-batch, on the entire dataset.\"\"\"\n",
        "        self.metrics=metrics\n",
        "        n_samples, n_features = X.shape\n",
        "        X_ori = X.copy()\n",
        "        # Normalize the data if necessary\n",
        "        X = self.normalize_data(X)\n",
        "\n",
        "        # Initialize W and H\n",
        "        W = np.abs(np.random.randn(n_samples, self.n_components))\n",
        "        self.H = np.abs(np.random.randn(self.n_components, n_features))\n",
        "\n",
        "        best_loss = float('inf')  # Initialize the best loss\n",
        "        no_improvement_count = 0  # Track how many iterations we had no improvement\n",
        "\n",
        "        epsilon = 1e-10  # Small constant to avoid division by zero\n",
        "\n",
        "        for n_iter in range(self.max_iter):\n",
        "            start_time = time.time()  # Start the timer for each iteration\n",
        "\n",
        "            # Add noise\n",
        "            X_noisy = self.add_noise(X)\n",
        "\n",
        "            # Compute WH\n",
        "            WH = np.dot(W, self.H)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = self.compute_loss(X_noisy, WH, W, self.H, n_features, n_samples)\n",
        "\n",
        "\n",
        "            # weighted\n",
        "            v_=self.update_weight(X_noisy, self.H, W)\n",
        "\n",
        "            if self.method == \"L2\":\n",
        "\n",
        "              # Update H\n",
        "              numerator_H = np.dot(W.T, X_noisy)\n",
        "              denominator_H = np.dot(W.T, np.dot(W, self.H)) + epsilon\n",
        "              self.H *= numerator_H / denominator_H\n",
        "\n",
        "              # Update W\n",
        "              numerator_W = np.dot(X_noisy, self.H.T)\n",
        "              denominator_W = np.dot(W, np.dot(self.H, self.H.T)) + epsilon\n",
        "              W *= numerator_W / denominator_W\n",
        "\n",
        "            elif self.method == \"L1\":\n",
        "\n",
        "              H_update_factor = np.dot(W.T, X_noisy* v_ )\n",
        "              H_denom = np.dot(W.T, np.dot(W, self.H)* v_) + epsilon\n",
        "              self.H *= H_update_factor / H_denom\n",
        "\n",
        "              W_update_factor = np.dot(X_noisy * v_, self.H.T)\n",
        "              W_denom = np.dot(np.dot(W, self.H)* v_ , self.H.T) + epsilon\n",
        "              W *= W_update_factor / W_denom\n",
        "\n",
        "\n",
        "            elif self.method == \"L21\":\n",
        "              # print(\"L21\")\n",
        "              D = np.diag(v_)  # Diagonal matrix D, where each entry comes from v_ (L2,1 update)\n",
        "\n",
        "                            # Update H (G in the equation)\n",
        "              numerator_H = np.dot(W.T, np.dot(X_noisy,D))\n",
        "              denominator_H = np.dot(W.T, np.dot(W, np.dot( self.H,D))) + epsilon\n",
        "              self.H *= numerator_H / denominator_H\n",
        "\n",
        "              # Update W (F in the equation)\n",
        "              numerator_W = np.dot(np.dot(X_noisy,D), self.H.T)\n",
        "              denominator_W = np.dot(W, np.dot(self.H, np.dot(D, self.H.T))) + epsilon\n",
        "              W *= numerator_W / denominator_W\n",
        "\n",
        "\n",
        "            else:\n",
        "              raise ValueError(f\"Unknown method: {self.method}\")\n",
        "\n",
        "            # Ensure non-negativity\n",
        "            W = np.maximum(W, epsilon)\n",
        "            self.H = np.maximum(self.H, epsilon)\n",
        "            # Compute RRE and other metrics\n",
        "            WH = np.dot(W, self.H)\n",
        "            rre = self.compute_rre(X_ori, self.denormalize_data(WH))\n",
        "            #rre = self.compute_rre(X, WH)\n",
        "            self.losses.append(loss)\n",
        "            self.rres.append(rre)\n",
        "\n",
        "            # At the end of each epoch, perform clustering and evaluate\n",
        "            if Y_true is not None:\n",
        "              if metrics:\n",
        "                Y_pred = self.assign_cluster_label(W, Y_true)\n",
        "                accuracy = accuracy_score(Y_true, Y_pred)\n",
        "                nmi = normalized_mutual_info_score(Y_true, Y_pred)\n",
        "                self.accuracies.append(accuracy)\n",
        "                self.nmis.append(nmi)\n",
        "                if self.verbose > 0 and (n_iter+1) % self.verbose == 0:\n",
        "                    print(f\"Epoch {n_iter}: Accuracy: {accuracy:.4f}, NMI: {nmi:.4f}, RRE: {rre:.4f}\")\n",
        "              else:\n",
        "                if self.verbose > 0 and (n_iter+1) % self.verbose == 0:\n",
        "                    Y_pred = self.assign_cluster_label(W, Y_true)\n",
        "                    accuracy = accuracy_score(Y_true, Y_pred)\n",
        "                    nmi = normalized_mutual_info_score(Y_true, Y_pred)\n",
        "                    self.accuracies.append(accuracy)\n",
        "                    self.nmis.append(nmi)\n",
        "                    print(f\"Epoch {n_iter+1}: Accuracy: {accuracy:.4f}, NMI: {nmi:.4f}, RRE: {rre:.4f}\")\n",
        "\n",
        "            elapsed_time = time.time() - start_time  # Calculate the elapsed time for the iteration\n",
        "            # if self.verbose > 0 and n_iter % self.verbose == 0:\n",
        "            #     print(f\"Iteration {n_iter}, Loss: {loss}, Time per iteration: {elapsed_time:.4f} seconds\")\n",
        "\n",
        "\n",
        "            # Check for early stopping\n",
        "            if self.early_stopping:\n",
        "                if best_loss - loss > self.min_delta:\n",
        "                    best_loss = loss  # Update the best loss\n",
        "                    no_improvement_count = 0  # Reset the counter for no improvement\n",
        "                else:\n",
        "                    no_improvement_count += 1  # Increment the no improvement count\n",
        "                    # print(f\"No improvement in loss for {no_improvement_count} iterations.\")\n",
        "                    if no_improvement_count >= self.patience:\n",
        "                        print(f\"Early stopping at iteration {n_iter+1}. Best loss: {best_loss}\")\n",
        "                        if Y_true is not None:\n",
        "                          if not metrics:\n",
        "                            Y_pred = self.assign_cluster_label(W, Y_true)\n",
        "                            accuracy = accuracy_score(Y_true, Y_pred)\n",
        "                            nmi = normalized_mutual_info_score(Y_true, Y_pred)\n",
        "                            self.accuracies.append(accuracy)\n",
        "                            self.nmis.append(nmi)\n",
        "                            print(f\"Epoch {n_iter+1}: Accuracy: {accuracy:.4f}, NMI: {nmi:.4f}, RRE: {rre:.4f}\")\n",
        "                        break  # Stop training early\n",
        "\n",
        "            # Check convergence\n",
        "            if loss < self.tol:\n",
        "                print(f'Converged at iteration {n_iter}')\n",
        "                break\n",
        "\n",
        "        return W, self.H, WH  # Also return WH (reconstructed data)\n",
        "\n",
        "    def plot_metrics(self):\n",
        "        \"\"\"Plot the recorded metrics over epochs\"\"\"\n",
        "        epochs = range(1, len(self.losses) + 1)\n",
        "\n",
        "        # Set global font size\n",
        "        plt.rcParams.update({'font.size': 14})\n",
        "\n",
        "        # Create a figure to hold all the metrics (2x2 layout)\n",
        "        plt.figure(figsize=(15, 10), dpi=300)\n",
        "\n",
        "        # Plot Loss over Epochs\n",
        "        plt.subplot(2, 2, 1)\n",
        "        plt.plot(epochs, self.losses, label='Loss')\n",
        "        plt.xlabel('Epochs', fontsize=12)\n",
        "        plt.ylabel('Loss', fontsize=12)\n",
        "        plt.title('Loss over Epochs', fontsize=14)\n",
        "        plt.legend(fontsize=12)\n",
        "\n",
        "        # Plot RRE over Epochs\n",
        "        plt.subplot(2, 2, 2)\n",
        "        plt.plot(epochs, self.rres, label='RRE')\n",
        "        plt.xlabel('Epochs', fontsize=12)\n",
        "        plt.ylabel('RRE', fontsize=12)\n",
        "        plt.title('RRE over Epochs', fontsize=14)\n",
        "        plt.legend(fontsize=12)\n",
        "\n",
        "        if self.metrics:\n",
        "            # Plot Accuracy over Epochs\n",
        "            if self.accuracies:\n",
        "                plt.subplot(2, 2, 3)\n",
        "                plt.plot(epochs, self.accuracies, label='Accuracy')\n",
        "                plt.xlabel('Epochs', fontsize=12)\n",
        "                plt.ylabel('Accuracy', fontsize=12)\n",
        "                plt.title('Accuracy over Epochs', fontsize=14)\n",
        "                plt.legend(fontsize=12)\n",
        "\n",
        "            # Plot NMI over Epochs\n",
        "            if self.nmis:\n",
        "                plt.subplot(2, 2, 4)\n",
        "                plt.plot(epochs, self.nmis, label='NMI')\n",
        "                plt.xlabel('Epochs', fontsize=12)\n",
        "                plt.ylabel('NMI', fontsize=12)\n",
        "                plt.title('NMI over Epochs', fontsize=14)\n",
        "                plt.legend(fontsize=12)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def get_metrics(self):\n",
        "        \"\"\"Return the recorded metrics\"\"\"\n",
        "        return self.losses, self.rres, self.accuracies, self.nmis\n",
        "\n",
        "    def get_final_metrics(self):\n",
        "        \"\"\"Return the final metrics after training\"\"\"\n",
        "        if self.accuracies and self.nmis:\n",
        "            return self.losses[-1], self.rres[-1], self.accuracies[-1], self.nmis[-1]\n",
        "        else:\n",
        "            return self.losses[-1], self.rres[-1], 0, 0\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample"
      ],
      "metadata": {
        "id": "XcsHet1aRrAU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrW8rs1Ogics"
      },
      "outputs": [],
      "source": [
        "from operator import is_\n",
        "# Process ORL dataset\n",
        "combined_images_ORL = orl_images\n",
        "# Apply NMF model on the ORL dataset\n",
        "n_samples_ORL, height_ORL, width_ORL = combined_images_ORL.shape\n",
        "X_ORL = combined_images_ORL.reshape(n_samples_ORL, height_ORL * width_ORL)\n",
        "\n",
        "imgsize=(height_ORL,width_ORL)\n",
        "n_components = 50  # Number of components for NMF\n",
        "noise_std = 0.1  # Noise standard deviation\n",
        "prob=0.05\n",
        "block_size=12\n",
        "num_blocks=1\n",
        "is_noise=True\n",
        "# noise_type=\"salt_and_pepper\"\n",
        "# noise_type=\"block\"\n",
        "noise_type=\"gaussian\"\n",
        "\n",
        "\n",
        "nmf_model_ORL = NMFWithNoise(n_components=n_components,noise_type=noise_type, noise_std=noise_std,prob=prob,block_size=block_size,num_blocks=num_blocks,method=\"L21\",is_noise=is_noise,imgsize=imgsize)\n",
        "W_full_ORL, H_full_ORL,WH_full = nmf_model_ORL.fit_transform(X_ORL,Y_true=orl_labels)\n",
        "print(\"ORL W (full) shape:\", W_full_ORL.shape)\n",
        "print(\"ORL H (full) shape:\", H_full_ORL.shape)\n",
        "nmf_model_ORL.plot_metrics()\n",
        "\n",
        "nmf_model_ORL = NMFWithNoise(n_components=n_components, noise_type=noise_type,noise_std=noise_std,prob=prob,block_size=block_size,num_blocks=num_blocks,method=\"L1\",is_noise=is_noise,imgsize=imgsize)\n",
        "W_full_ORL, H_full_ORL,WH_full = nmf_model_ORL.fit_transform(X_ORL,Y_true=orl_labels)\n",
        "print(\"ORL W (full) shape:\", W_full_ORL.shape)\n",
        "print(\"ORL H (full) shape:\", H_full_ORL.shape)\n",
        "nmf_model_ORL.plot_metrics()\n",
        "\n",
        "nmf_model_ORL = NMFWithNoise(n_components=n_components, noise_type=noise_type,noise_std=noise_std,prob=prob,block_size=block_size,num_blocks=num_blocks,method=\"L2\",is_noise=is_noise,imgsize=imgsize)\n",
        "W_full_ORL, H_full_ORL,WH_full = nmf_model_ORL.fit_transform(X_ORL,Y_true=orl_labels)\n",
        "print(\"ORL W (full) shape:\", W_full_ORL.shape)\n",
        "print(\"ORL H (full) shape:\", H_full_ORL.shape)\n",
        "nmf_model_ORL.plot_metrics()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8w8Ulk9wOM2L"
      },
      "source": [
        "## Image Restructure"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_images_Yale = yaleb_images\n",
        "n_samples_Yale, height_Yale, width_Yale = combined_images_Yale.shape\n",
        "X_Yale = combined_images_Yale.reshape(n_samples_Yale, height_Yale * width_Yale)\n",
        "imgsize=(42,48)\n",
        "n_components = 50  # Number of components for NMF\n",
        "noise_std = 0.05  # Noise standard deviation\n",
        "prob=0.05\n",
        "block_size=10\n",
        "num_blocks=1\n",
        "is_noise=True\n",
        "noise_type=\"gaussian\"\n",
        "nmf_model_Yale = NMFWithNoise(n_components=n_components,noise_type=noise_type, noise_std=noise_std,prob=prob,block_size=block_size,num_blocks=num_blocks,method=\"L21\",is_noise=False,imgsize=imgsize)\n",
        "W_full_Yale, H_full_Yale,WH_L21 = nmf_model_Yale.fit_transform(X_Yale,Y_true=yaleb_labels,metrics=False)\n",
        "\n",
        "nmf_model_Yale = NMFWithNoise(n_components=n_components, noise_type=noise_type,noise_std=noise_std,prob=prob,block_size=block_size,num_blocks=num_blocks,method=\"L1\",is_noise=False,imgsize=imgsize)\n",
        "W_full_Yale, H_full_Yale,WH_L1 = nmf_model_Yale.fit_transform(X_Yale,Y_true=yaleb_labels,metrics=False)\n",
        "\n",
        "nmf_model_Yale = NMFWithNoise(n_components=n_components, noise_type=noise_type,noise_std=noise_std,prob=prob,block_size=block_size,num_blocks=num_blocks,method=\"L2\",is_noise=False,imgsize=imgsize)\n",
        "W_full_Yale, H_full_Yale,WH_L2 = nmf_model_Yale.fit_transform(X_Yale,Y_true=yaleb_labels,metrics=False)\n",
        "\n",
        "\n",
        "nmf_model_Yale = NMFWithNoise(n_components=n_components, noise_type=noise_type,noise_std=noise_std,prob=prob,block_size=block_size,num_blocks=num_blocks,method=\"L21\",is_noise=True,imgsize=imgsize)\n",
        "W_full_Yale, H_full_Yale,WH_L21_Gaussian = nmf_model_Yale.fit_transform(X_Yale,Y_true=yaleb_labels,metrics=False)\n",
        "\n",
        "nmf_model_Yale = NMFWithNoise(n_components=n_components, noise_type=noise_type,noise_std=noise_std,prob=prob,block_size=block_size,num_blocks=num_blocks,method=\"L1\",is_noise=True,imgsize=imgsize)\n",
        "W_full_Yale, H_full_Yale,WH_L1_Gaussian = nmf_model_Yale.fit_transform(X_Yale,Y_true=yaleb_labels,metrics=False)\n",
        "\n",
        "nmf_model_Yale = NMFWithNoise(n_components=n_components, noise_type=noise_type,noise_std=noise_std,prob=prob,block_size=block_size,num_blocks=num_blocks,method=\"L2\",is_noise=True,imgsize=imgsize)\n",
        "W_full_Yale, H_full_Yale,WH_L2_Gaussian = nmf_model_Yale.fit_transform(X_Yale,Y_true=yaleb_labels,metrics=False)\n",
        "\n",
        "noise_type=\"block\"\n",
        "nmf_model_Yale = NMFWithNoise(n_components=n_components, noise_type=noise_type,noise_std=noise_std,prob=prob,block_size=block_size,num_blocks=num_blocks,method=\"L21\",is_noise=True,imgsize=imgsize)\n",
        "W_full_Yale, H_full_Yale,WH_L21_Block = nmf_model_Yale.fit_transform(X_Yale,Y_true=yaleb_labels,metrics=False)\n",
        "\n",
        "nmf_model_Yale = NMFWithNoise(n_components=n_components, noise_type=noise_type,noise_std=noise_std,prob=prob,block_size=block_size,num_blocks=num_blocks,method=\"L1\",is_noise=True,imgsize=imgsize)\n",
        "W_full_Yale, H_full_Yale,WH_L1_Block = nmf_model_Yale.fit_transform(X_Yale,Y_true=yaleb_labels,metrics=False)\n",
        "\n",
        "nmf_model_Yale = NMFWithNoise(n_components=n_components, noise_type=noise_type,noise_std=noise_std,prob=prob,block_size=block_size,num_blocks=num_blocks,method=\"L2\",is_noise=True,imgsize=imgsize)\n",
        "W_full_Yale, H_full_Yale,WH_L2_Block = nmf_model_Yale.fit_transform(X_Yale,Y_true=yaleb_labels,metrics=False)\n",
        "\n",
        "noise_type=\"salt_and_pepper\"\n",
        "nmf_model_Yale = NMFWithNoise(n_components=n_components, noise_type=noise_type,noise_std=noise_std,prob=prob,block_size=block_size,num_blocks=num_blocks,method=\"L21\",is_noise=True,imgsize=imgsize)\n",
        "W_full_Yale, H_full_Yale,WH_L21_Salt = nmf_model_Yale.fit_transform(X_Yale,Y_true=yaleb_labels,metrics=False)\n",
        "\n",
        "nmf_model_Yale = NMFWithNoise(n_components=n_components, noise_type=noise_type,noise_std=noise_std,prob=prob,block_size=block_size,num_blocks=num_blocks,method=\"L1\",is_noise=True,imgsize=imgsize)\n",
        "W_full_Yale, H_full_Yale,WH_L1_Salt = nmf_model_Yale.fit_transform(X_Yale,Y_true=yaleb_labels,metrics=False)\n",
        "\n",
        "nmf_model_Yale = NMFWithNoise(n_components=n_components, noise_type=noise_type,noise_std=noise_std,prob=prob,block_size=block_size,num_blocks=num_blocks,method=\"L2\",is_noise=True,imgsize=imgsize)\n",
        "W_full_Yale, H_full_Yale,WH_L2_Salt = nmf_model_Yale.fit_transform(X_Yale,Y_true=yaleb_labels,metrics=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Roqh0L5Dua8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WH_L21 = WH_L21.reshape(n_samples_Yale, height_Yale, width_Yale)\n",
        "WH_L1 = WH_L1.reshape(n_samples_Yale, height_Yale, width_Yale)\n",
        "WH_L2 = WH_L2.reshape(n_samples_Yale, height_Yale, width_Yale)\n",
        "WH_L1_Block = WH_L1_Block.reshape(n_samples_Yale, height_Yale, width_Yale)\n",
        "WH_L2_Block = WH_L2_Block.reshape(n_samples_Yale, height_Yale, width_Yale)\n",
        "WH_L21_Block = WH_L21_Block.reshape(n_samples_Yale, height_Yale, width_Yale)\n",
        "WH_L1_Gaussian = WH_L1_Gaussian.reshape(n_samples_Yale, height_Yale, width_Yale)\n",
        "WH_L2_Gaussian = WH_L2_Gaussian.reshape(n_samples_Yale, height_Yale, width_Yale)\n",
        "WH_L21_Gaussian = WH_L21_Gaussian.reshape(n_samples_Yale, height_Yale, width_Yale)\n",
        "WH_L1_Salt = WH_L1_Salt.reshape(n_samples_Yale, height_Yale, width_Yale)\n",
        "WH_L2_Salt = WH_L2_Salt.reshape(n_samples_Yale, height_Yale, width_Yale)\n",
        "WH_L21_Salt = WH_L21_Salt.reshape(n_samples_Yale, height_Yale, width_Yale)\n",
        "image= np.squeeze(combined_images_Yale[:1]/255)\n",
        "salt_and_pepper_img = add_salt_and_pepper_noise(image, prob=prob)\n",
        "guassian_img = add_gaussian_noise(image, noise_std=noise_std)\n",
        "print(combined_images_Yale.shape)\n",
        "block_img = add_block_occlusion_noise(image, block_size=block_size, num_blocks=num_blocks)\n",
        "\n",
        "list=[combined_images_Yale[:1],WH_L21[:1],WH_L1[:1],WH_L2[:1],\n",
        "   guassian_img,WH_L21_Gaussian[:1],WH_L1_Gaussian[:1],WH_L2_Gaussian[:1],\n",
        "   block_img ,WH_L21_Block[:1],WH_L1_Block[:1],WH_L2_Block[:1],\n",
        "   salt_and_pepper_img,WH_L21_Salt[:1],WH_L1_Salt[:1],WH_L2_Salt[:1]]\n"
      ],
      "metadata": {
        "id": "IOX_CpKXBEoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Define titles for each image\n",
        "titles = [\n",
        "    'Original Yale Image',\n",
        "    'Reconstructed L21',\n",
        "    'Reconstructed L1',\n",
        "    'Reconstructed L2',\n",
        "    'Gaussian Noisy Image',\n",
        "    'L21 Gaussian',\n",
        "    'L1 Gaussian',\n",
        "    'L2 Gaussian',\n",
        "    'Block Noisy Image',\n",
        "    'L21 Block',\n",
        "    'L1 Block',\n",
        "    'L2 Block',\n",
        "    'Salt&Pepper Noisy Image',\n",
        "    'L21 S&P',\n",
        "    'L1 S&P',\n",
        "    'L2 S&P'\n",
        "]\n",
        "\n",
        "# Create a 4x4 grid of subplots\n",
        "fig, axes = plt.subplots(4, 4, figsize=(12, 15), dpi=300)\n",
        "\n",
        "# Flatten the axes array into 1D for easy iteration\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Loop through each axis and image, display the image and its title\n",
        "for idx, ax in enumerate(axes):\n",
        "    img = list[idx]  # Replace 'list' with the actual list or array of images\n",
        "    img = np.squeeze(img)  # Remove single-dimensional entries from the image shape\n",
        "    ax.imshow(img, cmap='gray')  # Display the image in grayscale\n",
        "    ax.set_title(titles[idx], fontsize=20)  # Set the title for each subplot\n",
        "    ax.axis('off')  # Hide the axis\n",
        "\n",
        "# Adjust the spacing between subplots\n",
        "plt.tight_layout()\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "tGdQ5Ael3Owc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHzgvD7RVecp"
      },
      "source": [
        "# Experiments\n",
        "If you only want to check the results of the experiments, do not run this block. The experimental results have already been collected in a CSV file and will be plotted in the next block (Analytics and Figure)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sibnGTxFoK2X"
      },
      "source": [
        "## Base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0H3WcmwNVg0W"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def run_nmf_experiments(X_ORL, orl_labels, n_components=10,\n",
        "                        noise_type=\"block\",\n",
        "                        noise_std=0.01,\n",
        "                        prob=0.01,\n",
        "                        block_size=10,\n",
        "                        num_blocks=1,\n",
        "                        method=\"L2\",\n",
        "                        is_noise=True,\n",
        "                        imgsize=(30,37),\n",
        "                        n_experiments=5,\n",
        "                        sample_fraction=0.9,\n",
        "                        plot=True,\n",
        "                        metrics=True):\n",
        "\n",
        "    # Initialize lists to store final metrics for each experiment\n",
        "    final_losses_list = []\n",
        "    final_rres_list = []\n",
        "    final_accuracies_list = []\n",
        "    final_nmis_list = []\n",
        "\n",
        "    # Initialize lists to store metric curves for each experiment\n",
        "    all_losses = []\n",
        "    all_rres = []\n",
        "    all_accuracies = []\n",
        "    all_nmis = []\n",
        "\n",
        "    for i in range(n_experiments):\n",
        "        # Sample 90% of the data for training in each experiment\n",
        "        X_train, _, y_train, _ = train_test_split(X_ORL, orl_labels, train_size=sample_fraction, stratify=orl_labels)\n",
        "\n",
        "        # Initialize the NMFWithNoise mode\n",
        "        nmf_model = NMFWithNoise(n_components=n_components, noise_type=noise_type, noise_std=noise_std,\n",
        "                                 prob=prob, block_size=block_size, num_blocks=num_blocks,\n",
        "                                 method=method, is_noise=is_noise, imgsize=imgsize)\n",
        "\n",
        "        # fit model\n",
        "        nmf_model.fit_transform(X_train, Y_true=y_train, metrics=metrics)\n",
        "\n",
        "        # Get the final metrics from the experiment and save them\n",
        "        final_loss, final_rres, final_accuracy, final_nmi = nmf_model.get_final_metrics()\n",
        "        final_losses_list.append(final_loss)\n",
        "        final_rres_list.append(final_rres)\n",
        "        final_accuracies_list.append(final_accuracy)\n",
        "        final_nmis_list.append(final_nmi)\n",
        "\n",
        "        # Get the full metrics curves from the experiment\n",
        "        losses, rres, accuracies, nmis = nmf_model.get_metrics()\n",
        "        all_losses.append(losses)\n",
        "        all_rres.append(rres)\n",
        "        all_accuracies.append(accuracies)\n",
        "        all_nmis.append(nmis)\n",
        "\n",
        "        print(f\"Experiment {i+1} - Completed\")\n",
        "\n",
        "    # Compute the average final metrics across all experiments\n",
        "    avg_final_loss = np.mean(final_losses_list)\n",
        "    avg_final_rres = np.mean(final_rres_list)\n",
        "    avg_final_accuracy = np.mean(final_accuracies_list)\n",
        "    avg_final_nmi = np.mean(final_nmis_list)\n",
        "\n",
        "    # Compute the average final metrics across all experiments\n",
        "    print(\"Average Final Loss:\", avg_final_loss)\n",
        "    print(\"Average Final RREs:\", avg_final_rres)\n",
        "    print(\"Average Final Accuracy:\", avg_final_accuracy)\n",
        "    print(\"Average Final NMI:\", avg_final_nmi)\n",
        "\n",
        "    if plot:\n",
        "        # Set global font size\n",
        "        plt.rcParams.update({'font.size': 14})\n",
        "\n",
        "        # Plot the metric curves for each experiment\n",
        "        plt.figure(figsize=(12, 8), dpi=300)\n",
        "\n",
        "        # Plot Loss Curve\n",
        "        plt.subplot(2, 2, 1)\n",
        "        for i in range(n_experiments):\n",
        "            plt.plot(all_losses[i], label=f'Experiment {i+1}')\n",
        "        plt.title('Losses over Epochs', fontsize=16)\n",
        "        plt.xlabel('Epochs', fontsize=14)\n",
        "        plt.ylabel('Loss', fontsize=14)\n",
        "        plt.legend(fontsize=12)\n",
        "\n",
        "        # Plot rres Curve\n",
        "        plt.subplot(2, 2, 2)\n",
        "        for i in range(n_experiments):\n",
        "            plt.plot(all_rres[i], label=f'Experiment {i+1}')\n",
        "        plt.title('RREs over Epochs', fontsize=16)\n",
        "        plt.xlabel('Epochs', fontsize=14)\n",
        "        plt.ylabel('RRE', fontsize=14)\n",
        "        plt.legend(fontsize=12)\n",
        "\n",
        "        # Plot Accuracy Curve\n",
        "        plt.subplot(2, 2, 3)\n",
        "        for i in range(n_experiments):\n",
        "            plt.plot(all_accuracies[i], label=f'Experiment {i+1}')\n",
        "        plt.title('Accuracies over Epochs', fontsize=16)\n",
        "        plt.xlabel('Epochs', fontsize=14)\n",
        "        plt.ylabel('Accuracy', fontsize=14)\n",
        "        plt.legend(fontsize=12)\n",
        "\n",
        "        # Plot NMI Curve\n",
        "        plt.subplot(2, 2, 4)\n",
        "        for i in range(n_experiments):\n",
        "            plt.plot(all_nmis[i], label=f'Experiment {i+1}')\n",
        "        plt.title('NMIs over Epochs', fontsize=16)\n",
        "        plt.xlabel('Epochs', fontsize=14)\n",
        "        plt.ylabel('NMI', fontsize=14)\n",
        "        plt.legend(fontsize=12)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    return avg_final_loss, avg_final_rres, avg_final_accuracy, avg_final_nmi, final_losses_list, final_rres_list, final_accuracies_list, final_nmis_list\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biKG32X7sQ5s"
      },
      "outputs": [],
      "source": [
        "# Processing ORL dataset\n",
        "combined_images_ORL = orl_images\n",
        "n_samples_ORL, height_ORL, width_ORL = combined_images_ORL.shape\n",
        "X_ORL = combined_images_ORL.reshape(n_samples_ORL, height_ORL * width_ORL)\n",
        "\n",
        "\n",
        "n_components=10\n",
        "noise_type=\"block\"\n",
        "noise_std=0.01\n",
        "prob=0.01\n",
        "block_size=10\n",
        "num_blocks=1\n",
        "method=\"L2\"\n",
        "is_noise=False\n",
        "imgsize=(30,37)\n",
        "\n",
        "\n",
        "# Perform 5 experiments, sampling 90% of the data, and get the final results and complete metrics curves\n",
        "run_nmf_experiments(X_ORL, orl_labels, n_components=n_components,\n",
        "                       noise_type=noise_type,\n",
        "                       noise_std=noise_std,\n",
        "                       prob=prob,\n",
        "                       block_size=block_size,\n",
        "                       num_blocks=num_blocks,\n",
        "                       method=method,\n",
        "                       is_noise=is_noise,\n",
        "                       imgsize=imgsize,\n",
        "                       n_experiments=5,\n",
        "                       sample_fraction=0.9,\n",
        "                       plot=True,\n",
        "                       metrics=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaU0Q_RQzAkI"
      },
      "outputs": [],
      "source": [
        "combined_images_Yale = yaleb_images\n",
        "n_samples_Yale, height_Yale, width_Yale = combined_images_Yale.shape\n",
        "X_Yale = combined_images_Yale.reshape(n_samples_Yale, height_Yale * width_Yale)\n",
        "\n",
        "n_components=10\n",
        "noise_type=\"block\"\n",
        "noise_std=0.01\n",
        "prob=0.01\n",
        "block_size=10\n",
        "num_blocks=1\n",
        "method=\"L2\"\n",
        "is_noise=False\n",
        "imgsize=(42,48)\n",
        "\n",
        "\n",
        "# Perform 5 experiments, sampling 90% of the data, and get the final results and complete metrics curves\n",
        "run_nmf_experiments(X_Yale, yaleb_labels, n_components=n_components,\n",
        "                       noise_type=noise_type,\n",
        "                       noise_std=noise_std,\n",
        "                       prob=prob,\n",
        "                       block_size=block_size,\n",
        "                       num_blocks=num_blocks,\n",
        "                       method=method,\n",
        "                       is_noise=is_noise,\n",
        "                       imgsize=imgsize,\n",
        "                       n_experiments=5,\n",
        "                       sample_fraction=0.9,\n",
        "                       plot=True,\n",
        "                       metrics=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egBj306XXlPm"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def parameter_tuning_framework(X_ORL, orl_labels,\n",
        "                               n_components_list=[10],\n",
        "                               noise_type_list=[\"block\"],\n",
        "                               noise_std_list=[0.01],\n",
        "                               prob_list=[0.01],\n",
        "                               block_size_list=[10],\n",
        "                               num_blocks_list=[1],\n",
        "                               method_list=[\"L2\"],\n",
        "                               is_noise_list=[False],\n",
        "                               imgsize=(30,37),\n",
        "                               n_experiments=5,\n",
        "                               sample_fraction=0.9,\n",
        "                               output_csv=\"tuning_results.csv\"):\n",
        "    \"\"\"\n",
        "    A framework to run parameter tuning experiments on NMF with noise,\n",
        "    and save results in a CSV file. Also generates comparison box plots.\n",
        "\n",
        "    :param X_ORL: Input image data (ORL dataset)\n",
        "    :param orl_labels: Corresponding labels for ORL dataset\n",
        "    :param n_components_list: List of n_components values to try\n",
        "    :param noise_type_list: List of noise types to try\n",
        "    :param noise_std_list: List of noise standard deviations to try\n",
        "    :param prob_list: List of probabilities for salt-and-pepper noise to try\n",
        "    :param block_size_list: List of block sizes for block occlusion noise\n",
        "    :param num_blocks_list: List of the number of occlusion blocks to try\n",
        "    :param method_list: List of NMF methods (e.g., 'L2', 'L1', 'L21')\n",
        "    :param is_noise_list: List of boolean values to add noise or not\n",
        "    :param imgsize: Tuple representing image size (height, width)\n",
        "    :param n_experiments: Number of experiments for each parameter combination\n",
        "    :param sample_fraction: Fraction of data to sample for each experiment\n",
        "    :param output_csv: Filename for saving the results in a CSV file\n",
        "    \"\"\"\n",
        "\n",
        "    # Store parameter lists in a dictionary\n",
        "    parameters = {\n",
        "        'n_components': n_components_list,\n",
        "        'noise_type': noise_type_list,\n",
        "        'noise_std': noise_std_list,\n",
        "        'prob': prob_list,\n",
        "        'block_size': block_size_list,\n",
        "        'num_blocks': num_blocks_list,\n",
        "        'method': method_list,\n",
        "        'is_noise': is_noise_list,\n",
        "    }\n",
        "\n",
        "    # Get parameter names and their corresponding lists\n",
        "    param_names = list(parameters.keys())\n",
        "    param_values = list(parameters.values())\n",
        "\n",
        "    # Create a grid of all parameter combinations\n",
        "    param_grid = list(itertools.product(*param_values))\n",
        "\n",
        "    # Identify which parameters are changing across experiments\n",
        "    varying_parameters = [param for param in param_names if len(set(parameters[param])) > 1]\n",
        "\n",
        "    # Store results of all experiments\n",
        "    results = []\n",
        "\n",
        "    # Store metrics for all parameter combinations\n",
        "    all_metrics = {\n",
        "        'Loss': {},\n",
        "        'rres': {},\n",
        "        'Accuracy': {},\n",
        "        'NMI': {}\n",
        "    }\n",
        "\n",
        "    # Iterate over each parameter combination\n",
        "    for idx, param_tuple in enumerate(param_grid):\n",
        "        # Map parameter values to their respective names\n",
        "        params = dict(zip(param_names, param_tuple))\n",
        "\n",
        "        print(f\"\\nRunning parameter combination {idx+1}/{len(param_grid)}:\")\n",
        "        param_info = ', '.join([f\"{key}={value}\" for key, value in params.items()])\n",
        "        print(param_info)\n",
        "\n",
        "        # Extract parameters\n",
        "        n_components = params['n_components']\n",
        "        noise_type = params['noise_type']\n",
        "        noise_std = params['noise_std']\n",
        "        prob = params['prob']\n",
        "        block_size = params['block_size']\n",
        "        num_blocks = params['num_blocks']\n",
        "        method = params['method']\n",
        "        is_noise = params['is_noise']\n",
        "\n",
        "        # Run experiments for this parameter combination\n",
        "        avg_final_loss, avg_final_rres, avg_final_accuracy, avg_final_nmi, \\\n",
        "        final_losses_list, final_rres_list, final_accuracies_list, final_nmis_list = \\\n",
        "            run_nmf_experiments(X_ORL, orl_labels,\n",
        "                                n_components=n_components,\n",
        "                                noise_type=noise_type,\n",
        "                                noise_std=noise_std,\n",
        "                                prob=prob,\n",
        "                                block_size=block_size,\n",
        "                                num_blocks=num_blocks,\n",
        "                                method=method,\n",
        "                                is_noise=is_noise,\n",
        "                                imgsize=imgsize,\n",
        "                                n_experiments=n_experiments,\n",
        "                                sample_fraction=sample_fraction,\n",
        "                                plot=False,\n",
        "                                metrics=False)\n",
        "\n",
        "        # Store results and parameters\n",
        "        result = {\n",
        "            **params,\n",
        "            \"avg_final_loss\": avg_final_loss,\n",
        "            \"avg_final_rres\": avg_final_rres,\n",
        "            \"avg_final_accuracy\": avg_final_accuracy,\n",
        "            \"avg_final_nmi\": avg_final_nmi,\n",
        "            \"final_losses_list\": final_losses_list,\n",
        "            \"final_rres_list\": final_rres_list,\n",
        "            \"final_accuracies_list\": final_accuracies_list,\n",
        "            \"final_nmis_list\": final_nmis_list\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "        # Create a label for varying parameters\n",
        "        param_label = ', '.join([f\"{param}={params[param]}\" for param in varying_parameters])\n",
        "\n",
        "        # result store\n",
        "        metrics = {\n",
        "            'Loss': final_losses_list,\n",
        "            'rres': final_rres_list,\n",
        "            'Accuracy': final_accuracies_list,\n",
        "            'NMI': final_nmis_list\n",
        "        }\n",
        "        for metric_name, metric_values in metrics.items():\n",
        "            if param_label not in all_metrics[metric_name]:\n",
        "                all_metrics[metric_name][param_label] = []\n",
        "            all_metrics[metric_name][param_label].extend(metric_values)\n",
        "\n",
        "    # set global font size\n",
        "    plt.rcParams.update({'font.size': 14})\n",
        "\n",
        "    # Plot box plots with average metric lines for all experiments\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(20, 15), dpi=300)\n",
        "    metric_names = ['Loss', 'rres', 'Accuracy', 'NMI']\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for idx, metric_name in enumerate(metric_names):\n",
        "        param_results = all_metrics[metric_name]\n",
        "        labels = list(param_results.keys())\n",
        "        data = [param_results[label] for label in labels]\n",
        "        ax = axes[idx]\n",
        "\n",
        "        # Draw box plot\n",
        "        box = ax.boxplot(data, labels=labels, patch_artist=True)\n",
        "        # Get x-axis positions for box plots\n",
        "        means = [np.mean(d) for d in data]\n",
        "        # Get x-axis positions for box plots\n",
        "        x_positions = np.arange(1, len(labels) + 1)\n",
        "        # Plot mean line\n",
        "        ax.plot(x_positions, means, marker='o', linestyle='-', color='red', label='Mean')\n",
        "        ax.set_title(f'{metric_name} Parameter comparison', fontsize=18)\n",
        "        ax.set_ylabel(metric_name, fontsize=16)\n",
        "        ax.set_xlabel('Parameter combination', fontsize=16)\n",
        "        ax.set_xticks(x_positions)\n",
        "        ax.set_xticklabels(labels, rotation=30, ha='right', fontsize=12)\n",
        "        ax.legend(fontsize=12)\n",
        "        # Adjust font size of tick labels\n",
        "        ax.tick_params(axis='both', which='major', labelsize=14)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('metrics_comparison.png')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    # Convert results to a DataFrame and save to CSV\n",
        "    df_results = pd.DataFrame(results)\n",
        "    df_results.to_csv(output_csv, index=False)\n",
        "    print(f\"\\nExperiments completed, results have save in {output_csv}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Af2O05XtW4hr"
      },
      "outputs": [],
      "source": [
        "# Define Parameter list\n",
        "n_components_list = [5, 10, 15,20,25,30]\n",
        "method_list = [\"L2\"]\n",
        "noise_std_list = [0.01]\n",
        "noise_type_list = [\"block\"]\n",
        "prob_list = [0.01]\n",
        "block_size_list = [10]\n",
        "num_blocks_list = [1]\n",
        "is_noise_list = [False]\n",
        "\n",
        "# Call the fine-tuning function\n",
        "parameter_tuning_framework(X_ORL, orl_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(30,37),\n",
        "                           output_csv=\"tuning_results_orl.csv\")\n",
        "\n",
        "parameter_tuning_framework(X_Yale, yaleb_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list ,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(42,48),\n",
        "                           output_csv=\"tuning_results_yale.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYo0TbTXoBMA"
      },
      "source": [
        "## Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nepi7TtDnl9M"
      },
      "outputs": [],
      "source": [
        "# Define Parameter list\n",
        "n_components_list = [20]\n",
        "method_list = [\"L2\",\"L21\",\"L1\"]\n",
        "noise_std_list = [0.01]\n",
        "noise_type_list = [\"block\"]\n",
        "prob_list = [0.01]\n",
        "block_size_list = [10]\n",
        "num_blocks_list = [1]\n",
        "is_noise_list = [False]\n",
        "\n",
        "# Call the fine-tuning function\n",
        "parameter_tuning_framework(X_ORL, orl_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(30,37),\n",
        "                           output_csv=\"tuning_results_orl_method.csv\")\n",
        "\n",
        "parameter_tuning_framework(X_Yale, yaleb_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list ,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(42,48),\n",
        "                           output_csv=\"tuning_results_yale_method.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQUwHGwW1JjD"
      },
      "source": [
        "## Compoments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3II3-aT3L-D"
      },
      "source": [
        "### L2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1eC3Xtp3UgQ"
      },
      "outputs": [],
      "source": [
        "# Define Parameter list\n",
        "n_components_list = [5,10,15,20,25,30,35,40,45,50]\n",
        "method_list = [\"L2\"]\n",
        "noise_std_list = [0.01]\n",
        "noise_type_list = [\"block\"]\n",
        "prob_list = [0.01]\n",
        "block_size_list = [10]\n",
        "num_blocks_list = [1]\n",
        "is_noise_list = [False]\n",
        "\n",
        "# Call the fine-tuning function\n",
        "parameter_tuning_framework(X_ORL, orl_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(30,37),\n",
        "                           output_csv=\"tuning_results_orl_method_L2.csv\")\n",
        "\n",
        "parameter_tuning_framework(X_Yale, yaleb_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list ,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(42,48),\n",
        "                           output_csv=\"tuning_results_yale_method_L2.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qv2fb7ib3MKY"
      },
      "source": [
        "### L21"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9LUrNZD3U8D"
      },
      "outputs": [],
      "source": [
        "# Define Parameter list\n",
        "n_components_list = [5,10,15,20,25,30,35,40,45,50]\n",
        "method_list = [\"L21\"]\n",
        "noise_std_list = [0.01]\n",
        "noise_type_list = [\"block\"]\n",
        "prob_list = [0.01]\n",
        "block_size_list = [10]\n",
        "num_blocks_list = [1]\n",
        "is_noise_list = [False]\n",
        "\n",
        "# Call the fine-tuning function\n",
        "parameter_tuning_framework(X_ORL, orl_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(30,37),\n",
        "                           output_csv=\"tuning_results_orl_method_L21.csv\")\n",
        "\n",
        "parameter_tuning_framework(X_Yale, yaleb_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list ,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(42,48),\n",
        "                           output_csv=\"tuning_results_yale_method_L21.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhG8A_YF3MPq"
      },
      "source": [
        "### L1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lN3yG6Bf3VVB"
      },
      "outputs": [],
      "source": [
        "# Define Parameter list\n",
        "n_components_list = [5,10,15,20,25,30,35,40,45,50]\n",
        "method_list = [\"L1\"]\n",
        "noise_std_list = [0.01]\n",
        "noise_type_list = [\"block\"]\n",
        "prob_list = [0.01]\n",
        "block_size_list = [10]\n",
        "num_blocks_list = [1]\n",
        "is_noise_list = [False]\n",
        "\n",
        "# Call the fine-tuning function\n",
        "parameter_tuning_framework(X_ORL, orl_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(30,37),\n",
        "                           output_csv=\"tuning_results_orl_method_L1.csv\")\n",
        "\n",
        "parameter_tuning_framework(X_Yale, yaleb_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list ,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(42,48),\n",
        "                           output_csv=\"tuning_results_yale_method_L1.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bAbYDR1oFn_"
      },
      "source": [
        "## Noisy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZMkDqpP4EmS"
      },
      "source": [
        "### Block"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fEyTOkB4JwC"
      },
      "source": [
        "#### L2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKlCbOdp4Ixp"
      },
      "outputs": [],
      "source": [
        "# Define Parameter list\n",
        "n_components_list = [20]\n",
        "method_list = [\"L2\"]\n",
        "noise_std_list = [0.01]\n",
        "noise_type_list = [\"block\"]\n",
        "prob_list = [0.01]\n",
        "block_size_list = [10,12,14]\n",
        "num_blocks_list = [1,2]\n",
        "is_noise_list = [True]\n",
        "\n",
        "# Call the fine-tuning function\n",
        "parameter_tuning_framework(X_ORL, orl_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(30,37),\n",
        "                           output_csv=\"tuning_results_orl_method_L2_Block.csv\")\n",
        "\n",
        "parameter_tuning_framework(X_Yale, yaleb_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list ,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(42,48),\n",
        "                           output_csv=\"tuning_results_yale_method_L2_Block.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0IAsidn4NEE"
      },
      "source": [
        "#### L21"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cj2K07FQ4Odx"
      },
      "outputs": [],
      "source": [
        "# Define Parameter list\n",
        "n_components_list = [20]\n",
        "method_list = [\"L21\"]\n",
        "noise_std_list = [0.01]\n",
        "noise_type_list = [\"block\"]\n",
        "prob_list = [0.01]\n",
        "block_size_list = [10,12,14]\n",
        "num_blocks_list = [1,2]\n",
        "is_noise_list = [True]\n",
        "\n",
        "# Call the fine-tuning function\n",
        "parameter_tuning_framework(X_ORL, orl_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(30,37),\n",
        "                           output_csv=\"tuning_results_orl_method_L21_Block.csv\")\n",
        "\n",
        "parameter_tuning_framework(X_Yale, yaleb_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list ,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(42,48),\n",
        "                           output_csv=\"tuning_results_yale_method_L21_Block.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiLnUi5-4Epm"
      },
      "source": [
        "#### L1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKjua--N4QeZ"
      },
      "outputs": [],
      "source": [
        "# Define Parameter list\n",
        "n_components_list = [20]\n",
        "method_list = [\"L1\"]\n",
        "noise_std_list = [0.01]\n",
        "noise_type_list = [\"block\"]\n",
        "prob_list = [0.01]\n",
        "block_size_list = [10,12,14]\n",
        "num_blocks_list = [1,2]\n",
        "is_noise_list = [True]\n",
        "\n",
        "# Call the fine-tuning function\n",
        "parameter_tuning_framework(X_ORL, orl_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(30,37),\n",
        "                           output_csv=\"tuning_results_orl_method_L1_Block.csv\")\n",
        "\n",
        "parameter_tuning_framework(X_Yale, yaleb_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list ,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(42,48),\n",
        "                           output_csv=\"tuning_results_yale_method_L1_Block.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EpWWMXM4Y-B"
      },
      "source": [
        "### Gaussian"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF8pr6vN4Y-B"
      },
      "source": [
        "#### L2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X55UH00k4Y-B"
      },
      "outputs": [],
      "source": [
        "# Define Parameter list\n",
        "n_components_list = [20]\n",
        "method_list = [\"L2\"]\n",
        "noise_std_list = [0.01,0.02,0.05,0.1,0.15,0.2,0.25]\n",
        "noise_type_list = [\"gaussian\"]\n",
        "prob_list = [0.01]\n",
        "block_size_list = [10]\n",
        "num_blocks_list = [1]\n",
        "is_noise_list = [True]\n",
        "\n",
        "# Call the fine-tuning function\n",
        "parameter_tuning_framework(X_ORL, orl_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(30,37),\n",
        "                           output_csv=\"tuning_results_orl_method_L2_Gaussian.csv\")\n",
        "\n",
        "parameter_tuning_framework(X_Yale, yaleb_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list ,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(42,48),\n",
        "                           output_csv=\"tuning_results_yale_method_L2_Gaussian.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVq3qyjI4Y-B"
      },
      "source": [
        "#### L21"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTdeL82z4Y-B"
      },
      "outputs": [],
      "source": [
        "# Define Parameter list\n",
        "n_components_list = [20]\n",
        "method_list = [\"L21\"]\n",
        "noise_std_list = [0.01,0.02,0.05,0.1,0.15,0.2,0.25]\n",
        "noise_type_list = [\"gaussian\"]\n",
        "prob_list = [0.01]\n",
        "block_size_list = [10]\n",
        "num_blocks_list = [1]\n",
        "is_noise_list = [True]\n",
        "\n",
        "# Call the fine-tuning function\n",
        "parameter_tuning_framework(X_ORL, orl_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(30,37),\n",
        "                           output_csv=\"tuning_results_orl_method_L21_Gaussian.csv\")\n",
        "\n",
        "parameter_tuning_framework(X_Yale, yaleb_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list ,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(42,48),\n",
        "                           output_csv=\"tuning_results_yale_method_L21_Gaussian.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uywhP0PZ4Y-B"
      },
      "source": [
        "#### L1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEZFuaE94Y-B"
      },
      "outputs": [],
      "source": [
        "# Define Parameter list\n",
        "n_components_list = [20]\n",
        "method_list = [\"L1\"]\n",
        "noise_std_list = [0.01,0.02,0.05,0.1,0.15,0.2,0.25]\n",
        "noise_type_list = [\"gaussian\"]\n",
        "prob_list = [0.01]\n",
        "block_size_list = [10]\n",
        "num_blocks_list = [1]\n",
        "is_noise_list = [True]\n",
        "\n",
        "# Call the fine-tuning function\n",
        "parameter_tuning_framework(X_ORL, orl_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(30,37),\n",
        "                           output_csv=\"tuning_results_orl_method_L1_Gaussian.csv\")\n",
        "\n",
        "parameter_tuning_framework(X_Yale, yaleb_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list ,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(42,48),\n",
        "                           output_csv=\"tuning_results_yale_method_L1_Gaussian.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaSt-m2Qazyo"
      },
      "source": [
        "### Salt and Pepper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHS3GRs6azyp"
      },
      "source": [
        "#### L2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVbZI0Ehazyp"
      },
      "outputs": [],
      "source": [
        "# Define Parameter list\n",
        "n_components_list = [20]\n",
        "method_list = [\"L2\"]\n",
        "noise_std_list = [0.01]\n",
        "noise_type_list = [\"salt_and_pepper\"]\n",
        "prob_list = [0.01,0.02,0.05,0.1,0.15,0.2,0.25]\n",
        "block_size_list = [10]\n",
        "num_blocks_list = [1]\n",
        "is_noise_list = [True]\n",
        "\n",
        "# Call the fine-tuning function\n",
        "parameter_tuning_framework(X_ORL, orl_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(30,37),\n",
        "                           output_csv=\"tuning_results_orl_method_L2_salt_and_pepper.csv\")\n",
        "\n",
        "parameter_tuning_framework(X_Yale, yaleb_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list ,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(42,48),\n",
        "                           output_csv=\"tuning_results_yale_method_L2_salt_and_pepper.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN7sRzr3azyp"
      },
      "source": [
        "#### L21"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNXQWbU5azyp"
      },
      "outputs": [],
      "source": [
        "# Define Parameter list\n",
        "n_components_list = [20]\n",
        "method_list = [\"L21\"]\n",
        "noise_std_list = [0.01]\n",
        "noise_type_list = [\"salt_and_pepper\"]\n",
        "prob_list = [0.01,0.02,0.05,0.1,0.15,0.2,0.25]\n",
        "block_size_list = [10]\n",
        "num_blocks_list = [1]\n",
        "is_noise_list = [True]\n",
        "\n",
        "# Call the fine-tuning function\n",
        "parameter_tuning_framework(X_ORL, orl_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(30,37),\n",
        "                           output_csv=\"tuning_results_orl_method_L21_salt_and_pepper.csv\")\n",
        "\n",
        "parameter_tuning_framework(X_Yale, yaleb_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list ,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(42,48),\n",
        "                           output_csv=\"tuning_results_yale_method_L21_salt_and_pepper.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byRIWNKHazyq"
      },
      "source": [
        "#### L1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4X5VXToazyq"
      },
      "outputs": [],
      "source": [
        "# Define Parameter list\n",
        "n_components_list = [20]\n",
        "method_list = [\"L1\"]\n",
        "noise_std_list = [0.01]\n",
        "noise_type_list = [\"salt_and_pepper\"]\n",
        "prob_list = [0.01,0.02,0.05,0.1,0.15,0.2,0.25]\n",
        "block_size_list = [10]\n",
        "num_blocks_list = [1]\n",
        "is_noise_list = [True]\n",
        "\n",
        "# Call the fine-tuning function\n",
        "parameter_tuning_framework(X_ORL, orl_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(30,37),\n",
        "                           output_csv=\"tuning_results_orl_method_L1_salt_and_pepper.csv\")\n",
        "\n",
        "parameter_tuning_framework(X_Yale, yaleb_labels,\n",
        "                           n_components_list=n_components_list,\n",
        "                           noise_type_list=noise_type_list ,\n",
        "                           noise_std_list=noise_std_list,\n",
        "                           prob_list=prob_list ,\n",
        "                           block_size_list=block_size_list,\n",
        "                           num_blocks_list=num_blocks_list,\n",
        "                           method_list=method_list,\n",
        "                           is_noise_list=is_noise_list,\n",
        "                           imgsize=(42,48),\n",
        "                           output_csv=\"tuning_results_yale_method_L1_salt_and_pepper.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analytics and Figure\n",
        "Result table link is in here, if wget not work you can download from google drive and upload to content path\n",
        "https://drive.google.com/file/d/1i1uWAU95Joa2xBi82TiZ5grvR2tWJYuZ/view?usp=sharing"
      ],
      "metadata": {
        "id": "Z-nEd-wSIvG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Load dataset\n",
        "!wget --header=\"Host: drive.usercontent.google.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\" --header=\"Accept-Language: zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6\" --header=\"Cookie: HSID=AqK8DRIVZrNtHDQEM; SSID=AF8GbXclnoQKbndEK; APISID=eaYPuocswpo7W9-H/AOCjbMPSZJ096e5h4; SAPISID=xTIl5TE60VtPYf3j/A-54gZvfpsOMhgwjL; __Secure-1PAPISID=xTIl5TE60VtPYf3j/A-54gZvfpsOMhgwjL; __Secure-3PAPISID=xTIl5TE60VtPYf3j/A-54gZvfpsOMhgwjL; SID=g.a000nwiBaUsi6GOos5qwiCAzn7-ZhQm918oX0Xqog9XWXFAhtx4_ZngLciamwWcT5nURbScnKwACgYKATASAQASFQHGX2MiQUUCe2tzgS6X-NL3HA8prxoVAUF8yKr0RVnsjZil3lVmNMD_zlCe0076; __Secure-1PSID=g.a000nwiBaUsi6GOos5qwiCAzn7-ZhQm918oX0Xqog9XWXFAhtx4_-L5NGsjGkY8bODGhVP1CXgACgYKAWsSAQASFQHGX2MiqEWkSIH_mDn_XbSIn0PZ_RoVAUF8yKqh4hIaFLXTaFagmPAkmTpB0076; __Secure-3PSID=g.a000nwiBaUsi6GOos5qwiCAzn7-ZhQm918oX0Xqog9XWXFAhtx4_2k-SeL0aEAW1iN-ei2vX2wACgYKATQSAQASFQHGX2MiErvzoykH-Xm8oSXESUJuMRoVAUF8yKpsebmGTkobkLR6ev1dgZRn0076; SEARCH_SAMESITE=CgQIkZwB; AEC=AVYB7crFgh82n3n5Vx_S_wBruUtOWux2ywUcWao2Wu3a5ttBxbSiVjfvug; NID=517=v3lOLsYJtR3ePBYyWLtqb6Ep50822jejD4kimP34HSBk5wysbqvoCZp1ris5yXlihG9kp4f9YOJIV3bS3lO-Nlb2kfEBBqKGBdiMYreZtYUyFi9zUY2DiENGoXQNHtlelMKJR05us7b7sScDhACX1d2nAf0DLU-0__aQUYDSDlDmY2k7WtcJKs1ikdwoDpYVMKS0gp7yQjQDPjIEoGerZVdf1PvfgZTcr6S0jahiMUbuTyrZ_EU3ZP6CJ5w_OsxvlvYLGDywotqVG8K3aYf8-C_NBfcm3ptQK73ZCvTThSdODAruJCBgaWgF1DgWNIlu22fA_9td1COx8Afn8eSwWUk6RmtZ95L8oUVom7NvgfOlBRauTycqFQcwWoSkIjQG_3QSeShcM3UxyhgNsFx18eBDDF-0xH_oxtUrvOXuWaRr_vStKD1g0V1OFLFATAdxz9r_tFIRdY0CfkTZdwjqjnKtNn3ED32PA-kxShw3ENP689ReGz9vJnNeDOHbQw1dkn8H2RgVX3T-2pnQRRa-TAlk1zLpxYZDLK3f5cuufX1jGnwjR8inSTYWripWyz26p3JqzcGuQSEjcb81hPz2o1kSeGpEdlID5VeIp7ZQbE8-puFSOUUaHc-wwfEDHjiXga5678TLVpZOSr1_9nCqTYCFgV7QG-nfLwDIx-Y6MG4KswdhemlkvInb6_tfgROJd-uIFiO8KQRdBcdQkMdGGcowU8eGipshjNQ; __Secure-1PSIDTS=sidts-CjEBQlrA-FxW5AXGajBbPJqI0crdYtS70P9HW8t2uHcjNh33HrB2dM7PcpUEpf8JHQKIEAA; __Secure-3PSIDTS=sidts-CjEBQlrA-FxW5AXGajBbPJqI0crdYtS70P9HW8t2uHcjNh33HrB2dM7PcpUEpf8JHQKIEAA; SIDCC=AKEyXzXCcrAiLW4sWBMKrbgMuUPjbGtwqmvwLp9FADdFJynHVHW3M9PVxA4TkoRq9M6DSRXZdtcw6A; __Secure-1PSIDCC=AKEyXzWaKkDQWHQ2PB6mRwJvhMFlpCMOZZRifnqdDJ2N4RXS7ubnBg2EAEhgmy5Lgg9-_vFoO_Ny; __Secure-3PSIDCC=AKEyXzVjYdV_H6TlWTacmevOsenhWjF1QrvrVXwDnlYxuHNc6Hf8wGbaOZV7OwI6ZtHnF2zGm_iR\" --header=\"Connection: keep-alive\" \"https://drive.usercontent.google.com/download?id=1i1uWAU95Joa2xBi82TiZ5grvR2tWJYuZ&export=download&authuser=0&confirm=t&uuid=712246a0-9d13-4749-8b34-2902d915ce88&at=AN_67v0ukNxgN9H6M9dD2Js9Dr7u:1727430733542\" -c -O '5328.zip'\n",
        "!unzip 5328.zip\n"
      ],
      "metadata": {
        "id": "w2d2_6Wmw5EL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import ast\n",
        "import pandas as pd\n",
        "orl_method_L2=pd.read_csv(\"/content/5328/tuning_results_orl_method_L2.csv\")\n",
        "orl_method_L21=pd.read_csv(\"/content/5328/tuning_results_orl_method_L21.csv\")\n",
        "orl_method_L1=pd.read_csv(\"/content/5328/tuning_results_orl_method_L1.csv\")\n",
        "\n",
        "orl_method_L2_Block=pd.read_csv(\"/content/5328/tuning_results_orl_method_L2_Block.csv\")\n",
        "orl_method_L21_Block=pd.read_csv(\"/content/5328/tuning_results_orl_method_L21_Block.csv\")\n",
        "orl_method_L1_Block=pd.read_csv(\"/content/5328/tuning_results_orl_method_L1_Block.csv\")\n",
        "\n",
        "orl_method_L2_Gaussian=pd.read_csv(\"/content/5328/tuning_results_orl_method_L2_Gaussian.csv\")\n",
        "orl_method_L21_Gaussian=pd.read_csv(\"/content/5328/tuning_results_orl_method_L21_Gaussian.csv\")\n",
        "orl_method_L1_Gaussian=pd.read_csv(\"/content/5328/tuning_results_orl_method_L1_Gaussian.csv\")\n",
        "\n",
        "orl_method_L2_salt_and_pepper=pd.read_csv(\"/content/5328/tuning_results_orl_method_L2_salt_and_pepper.csv\")\n",
        "orl_method_L21_salt_and_pepper=pd.read_csv(\"/content/5328/tuning_results_orl_method_L21_salt_and_pepper.csv\")\n",
        "orl_method_L1_salt_and_pepper=pd.read_csv(\"/content/5328/tuning_results_orl_method_L1_salt_and_pepper.csv\")\n",
        "\n",
        "\n",
        "yale_method_L2=pd.read_csv(\"/content/5328/tuning_results_yale_method_L2.csv\")\n",
        "yale_method_L21=pd.read_csv(\"/content/5328/tuning_results_yale_method_L21.csv\")\n",
        "yale_method_L1=pd.read_csv(\"/content/5328/tuning_results_yale_method_L1.csv\")\n",
        "\n",
        "yale_method_L1_Block=pd.read_csv(\"/content/5328/tuning_results_yale_method_L1_Block.csv\")\n",
        "yale_method_L2_Block=pd.read_csv(\"/content/5328/tuning_results_yale_method_L2_Block.csv\")\n",
        "yale_method_L21_Block=pd.read_csv(\"/content/5328/tuning_results_yale_method_L21_Block.csv\")\n",
        "\n",
        "yale_method_L2_Gaussian=pd.read_csv(\"/content/5328/tuning_results_yale_method_L2_Gaussian.csv\")\n",
        "yale_method_L21_Gaussian=pd.read_csv(\"/content/5328/tuning_results_yale_method_L21_Gaussian.csv\")\n",
        "yale_method_L1_Gaussian=pd.read_csv(\"/content/5328/tuning_results_yale_method_L1_Gaussian.csv\")\n",
        "\n",
        "yale_method_L2_salt_and_pepper=pd.read_csv(\"/content/5328/tuning_results_yale_method_L2_salt_and_pepper.csv\")\n",
        "yale_method_L21_salt_and_pepper=pd.read_csv(\"/content/5328/tuning_results_yale_method_L21_salt_and_pepper.csv\")\n",
        "yale_method_L1_salt_and_pepper=pd.read_csv(\"/content/5328/tuning_results_yale_method_L1_salt_and_pepper.csv\")\n",
        "\n",
        "\n",
        "def str2list(df):\n",
        "  # Convert the string representations of lists in specific columns back to Python lists\n",
        "  df[\"final_losses_list\"]=df[\"final_losses_list\"].apply(ast.literal_eval)\n",
        "  df[\"final_rres_list\"]=df[\"final_rres_list\"].apply(ast.literal_eval)\n",
        "  df[\"final_accuracies_list\"]=df[\"final_accuracies_list\"].apply(ast.literal_eval)\n",
        "  df[\"final_nmis_list\"]=df[\"final_nmis_list\"].apply(ast.literal_eval)\n",
        "  # Calculate the mean of each list in the columns and store it in a new column\n",
        "  df[\"final losses mean\"] = df[\"final_losses_list\"].apply(lambda x: sum(x) / len(x))\n",
        "  df[\"final rres mean\"] = df[\"final_rres_list\"].apply(lambda x: sum(x) / len(x))\n",
        "  df[\"final accuracies mean\"] = df[\"final_accuracies_list\"].apply(lambda x: sum(x) / len(x))\n",
        "  df[\"final nmis mean\"] = df[\"final_nmis_list\"].apply(lambda x: sum(x) / len(x))\n",
        "  # Create a new column that combines block_size and num_blocks as a string\n",
        "  df['Block size and num blocks'] = df['block_size'].astype(str) + '_' + df['num_blocks'].astype(str)\n",
        "  return df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### ORL\n",
        "orl_method_L1=str2list(orl_method_L1)\n",
        "orl_method_L1_Block=str2list(orl_method_L1_Block)\n",
        "orl_method_L1_Gaussian=str2list(orl_method_L1_Gaussian)\n",
        "orl_method_L1_salt_and_pepper=str2list(orl_method_L1_salt_and_pepper)\n",
        "\n",
        "orl_method_L2=str2list(orl_method_L2)\n",
        "orl_method_L2_Block=str2list(orl_method_L2_Block)\n",
        "orl_method_L2_Gaussian=str2list(orl_method_L2_Gaussian)\n",
        "orl_method_L2_salt_and_pepper=str2list(orl_method_L2_salt_and_pepper)\n",
        "\n",
        "orl_method_L21=str2list(orl_method_L21)\n",
        "orl_method_L21_Block=str2list(orl_method_L21_Block)\n",
        "orl_method_L21_Gaussian=str2list(orl_method_L21_Gaussian)\n",
        "orl_method_L21_salt_and_pepper=str2list(orl_method_L21_salt_and_pepper)\n",
        "\n",
        "### Yale\n",
        "yale_method_L1=str2list(yale_method_L1)\n",
        "yale_method_L1_Block=str2list(yale_method_L1_Block)\n",
        "yale_method_L1_Gaussian=str2list(yale_method_L1_Gaussian)\n",
        "yale_method_L1_salt_and_pepper=str2list(yale_method_L1_salt_and_pepper)\n",
        "\n",
        "yale_method_L2=str2list(yale_method_L2)\n",
        "yale_method_L2_Block=str2list(yale_method_L2_Block)\n",
        "yale_method_L2_Gaussian=str2list(yale_method_L2_Gaussian)\n",
        "yale_method_L2_salt_and_pepper=str2list(yale_method_L2_salt_and_pepper)\n",
        "\n",
        "yale_method_L21=str2list(yale_method_L21)\n",
        "yale_method_L21_Block=str2list(yale_method_L21_Block)\n",
        "yale_method_L21_Gaussian=str2list(yale_method_L21_Gaussian)\n",
        "yale_method_L21_salt_and_pepper=str2list(yale_method_L21_salt_and_pepper)\n",
        "\n",
        "print(orl_method_L1)"
      ],
      "metadata": {
        "id": "8XjZbfSEI61S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Line"
      ],
      "metadata": {
        "id": "AIbpXH_NwvYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_n_components=[orl_method_L1,orl_method_L2,orl_method_L21,yale_method_L1,yale_method_L2,yale_method_L21]\n",
        "list_block=[orl_method_L1_Block,\n",
        "            orl_method_L2_Block,\n",
        "            orl_method_L21_Block,\n",
        "            yale_method_L1_Block,\n",
        "            yale_method_L2_Block,\n",
        "            yale_method_L21_Block]\n",
        "list_gaussian=[orl_method_L1_Gaussian,\n",
        "               orl_method_L2_Gaussian,\n",
        "               orl_method_L21_Gaussian,\n",
        "               yale_method_L1_Gaussian,\n",
        "               yale_method_L2_Gaussian,\n",
        "               yale_method_L21_Gaussian]\n",
        "list_salt_and_pepper=[orl_method_L1_salt_and_pepper,\n",
        "                      orl_method_L2_salt_and_pepper,\n",
        "                      orl_method_L21_salt_and_pepper,\n",
        "                      yale_method_L1_salt_and_pepper,\n",
        "                      yale_method_L2_salt_and_pepper,\n",
        "                      yale_method_L21_salt_and_pepper]\n"
      ],
      "metadata": {
        "id": "h-lTnSeo7NnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metrics_for_list(df_list, index, x_axis):\n",
        "    # Define the names of metrics to plot\n",
        "    metrics = ['final losses mean', 'final accuracies mean', 'final nmis mean', 'final rres mean']\n",
        "    titles = ['Final Losses Mean', 'Final Accuracies Mean', 'Final NMIs Mean', 'Final RREs Mean']\n",
        "\n",
        "    # Create a 2x2 grid of subplots, increase DPI for better clarity\n",
        "    fig, axs = plt.subplots(2, 2, figsize=(15, 10), dpi=300)\n",
        "\n",
        "    # Define a list of colors\n",
        "    colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown']\n",
        "\n",
        "    # Set font sizes for labels and titles\n",
        "    font_size = 20\n",
        "    title_size = 20\n",
        "    legend_size = 16\n",
        "\n",
        "    # Lists to collect handles and labels for the legend\n",
        "    handles = []\n",
        "    labels = []\n",
        "\n",
        "    # Iterate over metrics, creating one plot for each metric\n",
        "    for i, metric in enumerate(metrics):\n",
        "        ax1 = axs[i // 2, i % 2]  # The primary y-axis for the current subplot\n",
        "        ax2 = ax1.twinx()  # Create a secondary y-axis on the right side\n",
        "\n",
        "\n",
        "        l1, = ax1.plot(df_list[0][index], df_list[0][metric], label='ORL_L1', color=colors[3], linestyle='-', marker=\"s\", markersize=7, linewidth=3)\n",
        "        l2, = ax1.plot(df_list[1][index], df_list[1][metric], label='ORL_L2', color=colors[0], linestyle='-', marker=\"s\", markersize=7, linewidth=3)\n",
        "        l3, = ax1.plot(df_list[2][index], df_list[2][metric], label='ORL_L21', color=colors[1], linestyle='-', marker=\"s\", markersize=7, linewidth=3)\n",
        "        ax1.set_ylabel('ORLs ' + metric, color=\"black\", fontsize=font_size)\n",
        "        ax1.tick_params(axis='y', labelcolor=\"black\",labelsize=16)\n",
        "        ax1.set_xlabel(x_axis, fontsize=font_size)\n",
        "        ax1.tick_params(axis='x', labelsize=12)\n",
        "\n",
        "\n",
        "        l4, = ax2.plot(df_list[3][index], df_list[3][metric], label='YabeB_L1', color=colors[3], linestyle='-.', marker=\"*\", markersize=10, linewidth=3)\n",
        "        l5, = ax2.plot(df_list[4][index], df_list[4][metric], label='Yaleb_L2', color=colors[0], linestyle='-.', marker=\"*\", markersize=10, linewidth=3)\n",
        "        l6, = ax2.plot(df_list[5][index], df_list[5][metric], label='Yaleb_L21', color=colors[1], linestyle='-.', marker=\"*\", markersize=10, linewidth=3)\n",
        "        ax2.set_ylabel('YaleBs ' + metric, color=\"black\", fontsize=font_size)\n",
        "        ax2.tick_params(axis='y', labelcolor=\"black\",labelsize=16)\n",
        "\n",
        "        # Set the title for the subplot\n",
        "        ax1.set_title(titles[i], fontsize=title_size)\n",
        "        if i==0:\n",
        "          # Collect handles and labels for the legend from the first subplot\n",
        "          handles.extend([l1, l2, l3, l4, l5, l6])\n",
        "          labels.extend([l1.get_label(), l2.get_label(), l3.get_label(), l4.get_label(), l5.get_label(), l6.get_label()])\n",
        "\n",
        "    # Create a combined legend for all subplots, positioned above the plots\n",
        "    fig.legend(handles=handles, labels=labels, loc='upper center', bbox_to_anchor=(0.5, 1.04), ncol=6, fontsize=legend_size)\n",
        "\n",
        "    # Adjust layout to fit the plots and leave space for the legend\n",
        "    fig.tight_layout(rect=[0, 0, 1, 1])\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "rkUfzvlR2VzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metrics_for_list(list_n_components,'n_components',\"N components\")\n",
        "\n"
      ],
      "metadata": {
        "id": "VoxhlfgO9SEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metrics_for_list(list_block,'Block size and num blocks','White Block Noisy(size_num)')\n",
        "\n"
      ],
      "metadata": {
        "id": "aNKPKlsDsh9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plot_metrics_for_list(list_salt_and_pepper,'prob','Salt and Pepper Noisy(%)')\n",
        "\n"
      ],
      "metadata": {
        "id": "GIin-0NCsneW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metrics_for_list(list_gaussian,\"noise_std\",'Gaussian Noisy(std)')\n"
      ],
      "metadata": {
        "id": "eGaYIgASszLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metrics_for_list_for_dataset(df_list, index, x_axis,label):\n",
        "    # Define the names of metrics to plot\n",
        "    metrics = ['final losses mean', 'final accuracies mean', 'final nmis mean', 'final rres mean']\n",
        "    titles = ['Final Losses Mean', 'Final Accuracies Mean', 'Final NMIs Mean', 'Final RREs Mean']\n",
        "\n",
        "    # Create a 2x2 grid of subplots, increase DPI for better clarity\n",
        "    fig, axs = plt.subplots(2, 2, figsize=(15, 10), dpi=300)\n",
        "\n",
        "    # Define a list of colors for consistent plotting\n",
        "    colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown']\n",
        "\n",
        "    # Set font sizes for labels and titles\n",
        "    font_size = 20\n",
        "    title_size = 20\n",
        "    legend_size = 16\n",
        "\n",
        "    # Lists to collect handles and labels for the legend\n",
        "    handles = []\n",
        "    labels = []\n",
        "\n",
        "    # Iterate over metrics, creating one plot for each metric\n",
        "    for i, metric in enumerate(metrics):\n",
        "        ax1 = axs[i // 2, i % 2] # The primary y-axis for the current subplot\n",
        "\n",
        "        # Set y-axis\n",
        "        l1, = ax1.plot(df_list[0][index], df_list[0][metric], label=label+'_L1', color=colors[3], linestyle='-.', marker=\"*\", markersize=12, linewidth=3)\n",
        "        l2, = ax1.plot(df_list[1][index], df_list[1][metric], label=label+'_L2', color=colors[0], linestyle='-', marker=\"^\", markersize=8, linewidth=3)\n",
        "        l3, = ax1.plot(df_list[2][index], df_list[2][metric], label=label+'_L21', color=colors[1], linestyle='--', marker=\"s\", markersize=8, linewidth=3)\n",
        "        ax1.set_ylabel( metric, color=\"black\", fontsize=font_size)\n",
        "        ax1.tick_params(axis='y', labelcolor=\"black\",labelsize=16)\n",
        "        ax1.set_xlabel(x_axis, fontsize=font_size)\n",
        "        ax1.tick_params(axis='x', labelsize=12)\n",
        "\n",
        "\n",
        "        # Set the title for the subplot and fontsize\n",
        "        ax1.set_title(titles[i], fontsize=title_size)\n",
        "        if i==0:\n",
        "          # Collect handles and labels for the legend from the first subplot\n",
        "\n",
        "          handles.extend([l1, l2, l3])\n",
        "          labels.extend([l1.get_label(), l2.get_label(), l3.get_label()])\n",
        "\n",
        "    # Create a combined legend for all subplots, positioned above the plots\n",
        "    fig.legend(handles=handles, labels=labels, loc='upper center', bbox_to_anchor=(0.5, 1.04), ncol=3, fontsize=legend_size)\n",
        "\n",
        "    # Adjust layout to fit the plots and leave space for the legend\n",
        "    fig.tight_layout(rect=[0, 0, 1, 1])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Y1dK8iRIER4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_n_components_orl=[orl_method_L1,orl_method_L2,orl_method_L21,\n",
        "                       yale_method_L1,yale_method_L2,yale_method_L21]\n",
        "list_n_components_orl=[orl_method_L1,orl_method_L2,orl_method_L21,\n",
        "                       yale_method_L1,yale_method_L2,yale_method_L21]\n",
        "list_block_orl=[orl_method_L1_Block,\n",
        "        orl_method_L2_Block,\n",
        "        orl_method_L21_Block]\n",
        "list_gaussian_orl=[orl_method_L1_Gaussian,\n",
        "          orl_method_L2_Gaussian,\n",
        "          orl_method_L21_Gaussian]\n",
        "list_salt_and_pepper_orl=[orl_method_L1_salt_and_pepper,\n",
        "              orl_method_L2_salt_and_pepper,\n",
        "              orl_method_L21_salt_and_pepper]\n",
        "list_block_yaleb=[\n",
        "            yale_method_L1_Block,\n",
        "            yale_method_L2_Block,\n",
        "            yale_method_L21_Block]\n",
        "list_gaussian_yaleb=[\n",
        "               yale_method_L1_Gaussian,\n",
        "               yale_method_L2_Gaussian,\n",
        "               yale_method_L21_Gaussian]\n",
        "list_salt_and_pepper_yaleb=[\n",
        "                      yale_method_L1_salt_and_pepper,\n",
        "                      yale_method_L2_salt_and_pepper,\n",
        "                      yale_method_L21_salt_and_pepper]"
      ],
      "metadata": {
        "id": "iIOhsk0iDMbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metrics_for_list_for_dataset(list_block_orl,'Block size and num blocks','ORL White Block Noisy(size_num)',\"ORL\")\n",
        "plot_metrics_for_list_for_dataset(list_block_yaleb,'Block size and num blocks','YaleB White Block Noisy(size_num)',\"Yaleb\")"
      ],
      "metadata": {
        "id": "B_RdfQSfHEcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metrics_for_list_for_dataset(list_salt_and_pepper_orl,'prob','ORL Salt and Pepper Noisy(%)',\"ORL\")\n",
        "plot_metrics_for_list_for_dataset(list_salt_and_pepper_yaleb,'prob','YaleB Salt and Pepper Noisy(%)',\"Yaleb\")"
      ],
      "metadata": {
        "id": "Lt9RL3g3HEeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metrics_for_list_for_dataset(list_gaussian_orl,\"noise_std\",'ORL Gaussian Noisy(std)',\"ORL\")\n",
        "plot_metrics_for_list_for_dataset(list_gaussian_yaleb,\"noise_std\",'YaleB Gaussian Noisy(std)',\"Yaleb\")"
      ],
      "metadata": {
        "id": "aDeBAGeYHEhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boxplot"
      ],
      "metadata": {
        "id": "CqjR3Pgkv5J-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_metrics_grid(orl_datasets, yale_datasets):\n",
        "    fig, axs = plt.subplots(4, 3, figsize=(20, 20), dpi=300)  # layout\n",
        "    method=[\"L1\",\"L2\",\"L21\"]\n",
        "    # Set global font size\n",
        "    plt.rcParams.update({'font.size': 20})\n",
        "\n",
        "    for i in range(3):\n",
        "        # ORL Dataset：Acc and RRE\n",
        "        axs[0, i].boxplot(orl_datasets[i]['final_accuracies_list'], positions=orl_datasets[i]['n_components'], patch_artist=True, widths=2)\n",
        "        axs[0, i].plot(orl_datasets[i]['n_components'], orl_datasets[i]['final accuracies mean'], label='Mean Acc', color='red',linewidth=2)\n",
        "\n",
        "        axs[1, i].boxplot(orl_datasets[i]['final_rres_list'], positions=orl_datasets[i]['n_components'], patch_artist=True, widths=2)\n",
        "        axs[1, i].plot(orl_datasets[i]['n_components'], orl_datasets[i]['final rres mean'], label='Mean RRE', color='red',linewidth=2)\n",
        "\n",
        "        # YaleB Dataset：Acc and RRE\n",
        "        axs[2, i].boxplot(yale_datasets[i]['final_accuracies_list'], positions=yale_datasets[i]['n_components'], patch_artist=True, widths=2)\n",
        "        axs[2, i].plot(yale_datasets[i]['n_components'], yale_datasets[i]['final accuracies mean'], label='Mean Acc', color='red',linewidth=2)\n",
        "\n",
        "        axs[3, i].boxplot(yale_datasets[i]['final_rres_list'], positions=yale_datasets[i]['n_components'], patch_artist=True, widths=2)\n",
        "        axs[3, i].plot(yale_datasets[i]['n_components'], yale_datasets[i]['final rres mean'], label='Mean RRE', color='red',linewidth=2)\n",
        "\n",
        "        # Add legend\n",
        "        axs[0, i].legend(loc='upper right', fontsize=16)\n",
        "        axs[1, i].legend(loc='upper right', fontsize=16)\n",
        "        axs[2, i].legend(loc='upper right', fontsize=16)\n",
        "        axs[3, i].legend(loc='upper right', fontsize=16)\n",
        "\n",
        "        # Set title\n",
        "        axs[0, i].set_title(f'ORL Method {method[i]} - Acc', fontsize=20)\n",
        "        axs[1, i].set_title(f'ORL Method {method[i]} - RRE', fontsize=20)\n",
        "        axs[2, i].set_title(f'YaleB Method {method[i]} - Acc', fontsize=20)\n",
        "        axs[3, i].set_title(f'YaleB Method {method[i]} - RRE', fontsize=20)\n",
        "\n",
        "    # Set x axis title\n",
        "    for ax in axs.flat:\n",
        "        ax.set_xlabel('n_components', fontsize=20)\n",
        "\n",
        "    # Set y axis title\n",
        "    axs[0, 0].set_ylabel('ORL Accuracy', fontsize=20)\n",
        "    axs[1, 0].set_ylabel('ORL RRE', fontsize=20)\n",
        "    axs[2, 0].set_ylabel('YaleB Accuracy', fontsize=20)\n",
        "    axs[3, 0].set_ylabel('YaleB RRE', fontsize=20)\n",
        "\n",
        "    # tight layout\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "plot_metrics_grid(\n",
        "    [orl_method_L1, orl_method_L2, orl_method_L21],\n",
        "    [yale_method_L1, yale_method_L2, yale_method_L21]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "R9BFjv69iwty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_metrics_grid(orl_datasets, yale_datasets):\n",
        "    fig, axs = plt.subplots(2, 3, figsize=(20, 15), dpi=300)  # layout\n",
        "    method=[\"L1\",\"L2\",\"L21\"]\n",
        "    # Set global font size\n",
        "    plt.rcParams.update({'font.size': 20})\n",
        "\n",
        "    for i in range(3):\n",
        "        # Acc Dataset：ORL and YaleB\n",
        "        axs[0, i].boxplot(orl_datasets[i]['final_accuracies_list'], positions=orl_datasets[i]['n_components'], patch_artist=True, widths=2, boxprops=dict(color='black'))\n",
        "        axs[0, i].plot(orl_datasets[i]['n_components'], orl_datasets[i]['final accuracies mean'], label='ORL Acc Mean', color='red', linestyle='--',linewidth=2)\n",
        "\n",
        "        axs[0, i].boxplot(yale_datasets[i]['final_accuracies_list'], positions=yale_datasets[i]['n_components'], patch_artist=True, widths=2, boxprops=dict(color='black'))\n",
        "        axs[0, i].plot(yale_datasets[i]['n_components'], yale_datasets[i]['final accuracies mean'], label='YaleB Acc Mean', color='blue', linestyle='-.',linewidth=2)\n",
        "\n",
        "        # RRE Dataset：ORL and YaleB\n",
        "        axs[1, i].boxplot(orl_datasets[i]['final_rres_list'], positions=orl_datasets[i]['n_components'], patch_artist=True, widths=2, boxprops=dict(color='black'))\n",
        "        axs[1, i].plot(orl_datasets[i]['n_components'], orl_datasets[i]['final rres mean'], label='ORL RRE Mean', color='red', linestyle='--',linewidth=2)\n",
        "\n",
        "        axs[1, i].boxplot(yale_datasets[i]['final_rres_list'], positions=yale_datasets[i]['n_components'], patch_artist=True, widths=2, boxprops=dict(color='black'))\n",
        "        axs[1, i].plot(yale_datasets[i]['n_components'], yale_datasets[i]['final rres mean'], label='YaleB RRE Mean', color='blue', linestyle='-.',linewidth=2)\n",
        "\n",
        "        # Set titles\n",
        "        axs[0, i].set_title(f'Method {method[i]} - Acc', fontsize=24)\n",
        "        axs[1, i].set_title(f'Method {method[i]} - RRE', fontsize=24)\n",
        "\n",
        "        # Add legend\n",
        "        axs[0, i].legend(loc='center right', fontsize=16)\n",
        "        axs[1, i].legend(loc='center right', fontsize=16)\n",
        "\n",
        "    # Set x axis labels\n",
        "    for ax in axs.flat:\n",
        "        ax.set_xlabel('n_components', fontsize=20)\n",
        "\n",
        "    # Set y axis labels\n",
        "    axs[0, 0].set_ylabel('Accuracy', fontsize=20)\n",
        "    axs[1, 0].set_ylabel('RRE', fontsize=20)\n",
        "\n",
        "    # Adjustment Layout\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_metrics_grid(\n",
        "    [orl_method_L1, orl_method_L2, orl_method_L21],\n",
        "    [yale_method_L1, yale_method_L2, yale_method_L21]\n",
        ")\n"
      ],
      "metadata": {
        "id": "6QHLQMUIq78A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_metrics_grid_single(orl_datasets,dataset_name):\n",
        "    fig, axs = plt.subplots(4, 3, figsize=(20, 20), dpi=300)  # Layout\n",
        "    method=[\"L1\",\"L2\",\"L21\"]\n",
        "    # Set global font size\n",
        "    plt.rcParams.update({'font.size': 20})\n",
        "\n",
        "    for i in range(3):\n",
        "        # Acc, RRE, Loss and NMI\n",
        "        axs[0, i].boxplot(orl_datasets[i]['final_accuracies_list'], positions=orl_datasets[i]['n_components'], patch_artist=True, widths=2)\n",
        "        axs[0, i].plot(orl_datasets[i]['n_components'], orl_datasets[i]['final accuracies mean'], label='Mean Acc', color='red',linewidth=2)\n",
        "\n",
        "        axs[1, i].boxplot(orl_datasets[i]['final_rres_list'], positions=orl_datasets[i]['n_components'], patch_artist=True, widths=2)\n",
        "        axs[1, i].plot(orl_datasets[i]['n_components'], orl_datasets[i]['final rres mean'], label='Mean RRE', color='red',linewidth=2)\n",
        "\n",
        "        axs[2, i].boxplot(orl_datasets[i]['final_losses_list'], positions=orl_datasets[i]['n_components'], patch_artist=True, widths=2)\n",
        "        axs[2, i].plot(orl_datasets[i]['n_components'], orl_datasets[i]['final losses mean'], label='Mean Loss', color='red',linewidth=2)\n",
        "\n",
        "        axs[3, i].boxplot(orl_datasets[i]['final_nmis_list'], positions=orl_datasets[i]['n_components'], patch_artist=True, widths=2)\n",
        "        axs[3, i].plot(orl_datasets[i]['n_components'], orl_datasets[i]['final nmis mean'], label='Mean NMI', color='red',linewidth=2)\n",
        "\n",
        "        # Add legend\n",
        "        axs[0, i].legend(loc='upper right', fontsize=16)\n",
        "        axs[1, i].legend(loc='upper right', fontsize=16)\n",
        "        axs[2, i].legend(loc='upper right', fontsize=16)\n",
        "        axs[3, i].legend(loc='upper right', fontsize=16)\n",
        "\n",
        "        # Set titles\n",
        "        axs[0, i].set_title(f'{dataset_name} Method {method[i]} - Acc', fontsize=20)\n",
        "        axs[1, i].set_title(f'{dataset_name} Method {method[i]} - RRE', fontsize=20)\n",
        "        axs[2, i].set_title(f'{dataset_name} Method {method[i]} - Loss', fontsize=20)\n",
        "        axs[3, i].set_title(f'{dataset_name} Method {method[i]} - NMI', fontsize=20)\n",
        "\n",
        "    # Set x axis labels\n",
        "    for ax in axs.flat:\n",
        "        ax.set_xlabel('n_components', fontsize=20)\n",
        "\n",
        "    # Set y axis labels\n",
        "    axs[0, 0].set_ylabel(dataset_name+' Accuracy', fontsize=20)\n",
        "    axs[1, 0].set_ylabel(dataset_name+' RRE', fontsize=20)\n",
        "    axs[2, 0].set_ylabel(dataset_name+' Loss', fontsize=20)\n",
        "    axs[3, 0].set_ylabel(dataset_name+' NMI', fontsize=20)\n",
        "\n",
        "    # Adjustment Layout\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plot_metrics_grid_single(\n",
        "    [orl_method_L1, orl_method_L2, orl_method_L21],\"ORL\"\n",
        ")\n",
        "plot_metrics_grid_single(\n",
        "    [yale_method_L1, yale_method_L2, yale_method_L21],\"YaleB\"\n",
        ")"
      ],
      "metadata": {
        "id": "hl0JAiljSoOd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "f6p62zfR0CXK",
        "g-O68j77_siH",
        "_GWqdj65gCWM",
        "1e33PFIG1U6A",
        "XcsHet1aRrAU",
        "8w8Ulk9wOM2L",
        "QHzgvD7RVecp",
        "sibnGTxFoK2X",
        "aYo0TbTXoBMA",
        "Qv2fb7ib3MKY",
        "UhG8A_YF3MPq",
        "3bAbYDR1oFn_",
        "9ZMkDqpP4EmS",
        "-fEyTOkB4JwC",
        "K0IAsidn4NEE",
        "wiLnUi5-4Epm",
        "ZF8pr6vN4Y-B",
        "oVq3qyjI4Y-B",
        "uywhP0PZ4Y-B",
        "DaSt-m2Qazyo",
        "YHS3GRs6azyp",
        "yN7sRzr3azyp",
        "byRIWNKHazyq",
        "Z-nEd-wSIvG6",
        "AIbpXH_NwvYf",
        "CqjR3Pgkv5J-"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}